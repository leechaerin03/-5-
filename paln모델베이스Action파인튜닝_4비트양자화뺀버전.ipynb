{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leechaerin03/-5-/blob/main/paln%EB%AA%A8%EB%8D%B8%EB%B2%A0%EC%9D%B4%EC%8A%A4Action%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D_4%EB%B9%84%ED%8A%B8%EC%96%91%EC%9E%90%ED%99%94%EB%BA%80%EB%B2%84%EC%A0%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zBl9BsSuhc-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "433fce82550f49ca8abca1a61393bb31",
            "0e2487c169354c329f5d9a8c616ceb42",
            "c1d0bc1558d04983b515f1ec49ea1b85",
            "7220bd378c8a4bcd9862da23cfc5f5f4",
            "4dc3e08c903a4f54852ba1ffe2e53d47",
            "b6811149866842e59fdc8b39ead3e284",
            "47e98a7a8e4440188b2cb5877e750143",
            "e5b16a11806840769bd72c6570ba3920",
            "b20074e7cca54adf9a287ffe67fc012e",
            "7f9689ad68e44ac0b716c0c63919cd9d",
            "18e1d224a3be493f8ba1566d8f81bca5",
            "21bc55f894764f1590cc070f337a0322",
            "c45a2655c38746fa900eab450500c405",
            "cb2937bc11e5424bba935fccf2613d82",
            "b71ae1f0e60c48ffa477d3270abb796c",
            "9e6e798befd74335a66e95dff6fb30e6",
            "f61ae4b4efb441bfba541934b89f836b",
            "f1e0675587ee4572aebb019ec1cf5871",
            "a7b3b49d59f74af2adda1464db01ceb6",
            "c53192f8cfcd4d029cb8afb307972248"
          ]
        },
        "outputId": "84239953-1493-41c4-a992-470792bd8bb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "433fce82550f49ca8abca1a61393bb31"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHA8bmWriZmq",
        "outputId": "7d1b2f2e-39a8-4a96-87be-07220dc5375b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.44.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# LLM 모니터링\n",
        "wandb.login(key=\"9ed675d942c745bf3fdf524bba1fcd137e6e81ab\")\n",
        "run = wandb.init(project='Fine tuning  LAM2', job_type='training', anonymous='allow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "R16JHGGki3DV",
        "outputId": "3b0c0c32-f360-41b1-ea52-8e74fdf19f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251121_021039-ltxu9fsh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2/runs/ltxu9fsh?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab' target=\"_blank\">graceful-jazz-9</a></strong> to <a href='https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab' target=\"_blank\">https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2/runs/ltxu9fsh?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab' target=\"_blank\">https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2/runs/ltxu9fsh?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Do NOT share these links with anyone. They can be used to claim your runs."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gagDJf1PwAMi",
        "outputId": "ee903df8-7fed-4e2c-d5aa-4994f2e0ad3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LoRA 어댑터 적용 후 학습 가능한 파라미터 ---\n",
            "trainable params: 23,003,136 || all params: 2,109,982,464 || trainable%: 1.0902\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer\n",
        ")\n",
        "from peft import (\n",
        "    get_peft_model,\n",
        "    LoraConfig\n",
        ")\n",
        "\n",
        "\n",
        "# --- 1. 모델 및 토크나이저 ID ---\n",
        "hub_repo_name = \"leeChaerin/PlanModel_v1\"\n",
        "\n",
        "\n",
        "# --- 3. 모델 로드 (수정됨) ---\n",
        "# 4비트 양자화 설정을 적용하고, .to(\"cuda\") 대신 device_map=\"auto\" 사용\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    hub_repo_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# --- 4. 토크나이저 로드 (수정됨) ---\n",
        "# padding_side는 그대로 두되, pad_token은 None일 경우에만 설정\n",
        "tokenizer = AutoTokenizer.from_pretrained(hub_repo_name, padding_side=\"left\")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(\"Tokenizer pad_token이 eos_token으로 설정되었습니다.\")\n",
        "\n",
        "# --- 5. (★필수★) LoRA 어댑터 적용 ---\n",
        "# 이 부분이 '...does not require grad...' 에러를 해결합니다.\n",
        "# 4비트로 '동결된' 모델 위에 학습 가능한 새 레이어(어댑터)를 추가합니다.\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"], # PlanModel_v1의 기반 모델(Kanana) 기준\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# 모델에 LoRA 어댑터 적용\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# --- 6. 준비 완료 ---\n",
        "print(\"\\n--- LoRA 어댑터 적용 후 학습 가능한 파라미터 ---\")\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIi-EnI8xxlT",
        "outputId": "1f5a6fff-0239-4958-a998-2a5983a55644"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[128000, 128009]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tokenizer.encode(tokenizer.eos_token)\n",
        "#base모델은 eos 토큰이 128001임 왜 차이나는진 모르겠음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WmRs0_YyBGN",
        "outputId": "56456f47-86c5-434d-92eb-1c172295382c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
            "    1.  **Plan Generation:**\n",
            "      If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
            "      You MUST respond with the complete `{\"task_plan\": [{\"step_id\": , \"description\":}...]}` JSON for the entire task.\n",
            "      If the user requests a specific course, include the specific course name in the plan description.\n",
            "\n",
            "    2.  **Action Generation:**\n",
            "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
            "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.\n",
            "      For input actions, ensure the `value` field matches the specific data from the plan.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\",\n",
        "    \"content\": \"\"\"You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
        "    1.  **Plan Generation:**\n",
        "      If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
        "      You MUST respond with the complete `{\"task_plan\": [{\"step_id\": , \"description\":}...]}` JSON for the entire task.\n",
        "      If the user requests a specific course, include the specific course name in the plan description.\n",
        "\n",
        "    2.  **Action Generation:**\n",
        "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
        "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.\n",
        "      For input actions, ensure the `value` field matches the specific data from the plan.\"\"\"}\n",
        "]\n",
        "\n",
        "tokens = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "print(tokens)\n",
        "#print(tokenizer.encode(tokens, add_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_TEXT = (\n",
        "    \"\"\"You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
        "    1.  **Plan Generation:**\n",
        "      If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
        "      You MUST respond with the complete `{\"task_plans\": [...]}` JSON for the entire task.\n",
        "\n",
        "    2.  **Action Generation:**\n",
        "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
        "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "LbyCSwm8QF8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5XenGuZyMNh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "e204c857-6e71-40e7-ece4-b36f6c1453c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.jsonl 업로드...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dfa55de2-9582-417a-94cb-92348789448a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dfa55de2-9582-417a-94cb-92348789448a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.jsonl to test (2).jsonl\n",
            "데이터를 로드하며 타입을 문자열로 통일합니다...\n",
            "\n",
            "--- 수정된 데이터로 로드 성공! ---\n",
            "Dataset({\n",
            "    features: ['prompt', 'output'],\n",
            "    num_rows: 15\n",
            "})\n",
            "\n",
            "[Row 0 예시] (Query -> Plan)\n",
            "{'prompt': '{\"user_request\": \"불교동아리\"}', 'output': '{\"task_plan\": [{\"step_id\": \"1\", \"task_plan\": \"좌측 메뉴에서 \\'학생신청(기타)\\'를 펼친다\"}, {\"step_id\": \"2\", \"task_plan\": \"하위 메뉴 \\'불교동아리가입\\'을 클릭한다\"}]}'}\n",
            "\n",
            "[Row 1 예시] (Plan+State -> Action)\n",
            "{'prompt': '{\"user_request\": \"불교동아리\", \"task_plan\": \"좌측 메뉴에서 \\'학생신청(기타)\\'를 펼친다\", \"step_id\": \"1\", \"observations\": {\"sidebar\": [{\"label\": \"개인정보수집동의\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"【학생신청】신청함\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"【학생신청】진행함\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"【학생신청】완료함\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"학생신청(기타)\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"학적/확인서\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"수강신청\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"수업/강의평가\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"성적\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"장학\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"등록\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"교직\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"졸업\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"공학교육인증\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"현장실습\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"예비군\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"교육센터\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"써머스쿨\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"남산학사\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"충무학사\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"고양학사\", \"expanded\": false, \"checked\": false, \"sub_items\": []}, {\"label\": \"공지사항\", \"expanded\": true, \"checked\": false, \"sub_items\": [{\"label\": \"공지사항조회\", \"expanded\": false, \"checked\": true, \"sub_items\": []}]}]}}', 'output': '{\"function\": \"click\", \"control_label\": \"학생신청(기타)\", \"control_type\": \"tree-item\", \"args\": {\"role\": \"treeitem\", \"aria-label\": \"학생신청(기타)\"}, \"status\": \"CONTINUE\"}'}\n",
            "\n",
            "총 15개 데이터 로드 완료.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "print(\"train_data.jsonl 업로드...\")\n",
        "uploaded = files.upload()\n",
        "DATA_PATH = list(uploaded.keys())[0]\n",
        "\n",
        "fixed_data = []\n",
        "print(\"데이터를 로드하며 타입을 문자열로 통일합니다...\")\n",
        "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            row = json.loads(line)\n",
        "\n",
        "            if isinstance(row.get('prompt'), dict):\n",
        "                row['prompt'] = json.dumps(row['prompt'], ensure_ascii=False)\n",
        "\n",
        "            if isinstance(row.get('output'), dict):\n",
        "                row['output'] = json.dumps(row['output'], ensure_ascii=False)\n",
        "\n",
        "            if 'prompt' in row and 'output' in row:\n",
        "                fixed_data.append(row)\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"JSON 파싱 오류 무시: {line}\")\n",
        "\n",
        "raw = Dataset.from_list(fixed_data)\n",
        "\n",
        "print(\"\\n--- 수정된 데이터로 로드 성공! ---\")\n",
        "print(raw)\n",
        "print(\"\\n[Row 0 예시] (Query -> Plan)\")\n",
        "print(raw[0])\n",
        "print(\"\\n[Row 1 예시] (Plan+State -> Action)\")\n",
        "print(raw[1])\n",
        "print(f\"\\n총 {len(raw)}개 데이터 로드 완료.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGl1PAKbyQcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c7c108-09d0-4499-eb73-cb00f252f3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples: 15\n",
            "max_length: 1451\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "qna_list = []\n",
        "\n",
        "SYSTEM_TEXT = (\n",
        "     \"\"\"You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
        "    1.  **Plan Generation:**\n",
        "      If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
        "      You MUST respond with the complete `{\"task_plan\": [{\"step_id\": , \"description\":}...]}` JSON for the entire task.\n",
        "      If the user requests a specific course, include the specific course name in the plan description.\n",
        "\n",
        "    2.  **Action Generation:**\n",
        "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
        "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.\n",
        "      For input actions, ensure the `value` field matches the specific data from the plan.\"\"\"\n",
        ")\n",
        "\n",
        "for i in range(len(raw)):\n",
        "    state = raw[i][\"prompt\"]   # 사용자 입력(프롬프트)\n",
        "    action = raw[i][\"output\"]  # 정답(assistant 응답)\n",
        "\n",
        "    # 1) messages에는 system + user만!\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_TEXT},\n",
        "        {\"role\": \"user\",   \"content\": state},\n",
        "    ]\n",
        "\n",
        "    # 2) 마지막 user까지 템플릿 적용 + assistant가 생성될 자리 열기\n",
        "    prompt_ids = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=True, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    # 3) 정답 토큰은 별도로 인코딩해서 뒤에 붙임 (eos 권장)\n",
        "    answer_ids = tokenizer.encode(\n",
        "        (action or \"\") + (tokenizer.eos_token or \"\"),\n",
        "        add_special_tokens=False\n",
        "    )\n",
        "\n",
        "    # 4) concat\n",
        "    input_ids = prompt_ids + answer_ids\n",
        "\n",
        "    # (선택) 평가/디버그용으로 원문 문자열도 보관하고 싶다면:\n",
        "    prompt_str = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    answer_str = ((action or \"\") + (tokenizer.eos_token or \"\"))\n",
        "    input_str  = prompt_str + answer_str\n",
        "\n",
        "    qna_list.append({\n",
        "        \"prompt_ids\": prompt_ids,\n",
        "        \"answer_ids\": answer_ids,\n",
        "        \"input_ids\":  input_ids,\n",
        "        \"prompt_str\": prompt_str,\n",
        "        \"answer_str\": answer_str,\n",
        "        \"input_str\":  input_str,\n",
        "    })\n",
        "\n",
        "# 길이 통계(패딩 전에 참고용)\n",
        "max_length = max(len(x[\"input_ids\"]) for x in qna_list)\n",
        "print(\"samples:\", len(qna_list))\n",
        "print(\"max_length:\", max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1HAKB6GyUBe"
      },
      "outputs": [],
      "source": [
        "pad_id = tokenizer.pad_token_id\n",
        "assert pad_id is not None, \"pad_token이 설정돼 있어야 합니다.\"\n",
        "\n",
        "class SFTDataset(Dataset):\n",
        "    def __init__(self, items, max_length):\n",
        "        self.inputs = []\n",
        "        self.attns  = []\n",
        "        self.labels = []\n",
        "\n",
        "        for ex in items:\n",
        "            ids = ex[\"input_ids\"]\n",
        "\n",
        "            # 트렁케이션/패딩\n",
        "            if len(ids) > max_length:\n",
        "                ids = ids[-max_length:]  # 뒤를 보존(정답이 뒤에 있으므로)\n",
        "\n",
        "            attn = [1] * len(ids)\n",
        "            pad_len = max_length - len(ids)\n",
        "            if pad_len > 0:\n",
        "                ids  = ids  + [pad_id] * pad_len\n",
        "                attn = attn + [0]      * pad_len\n",
        "\n",
        "            # 레이블: 프롬프트는 -100, 정답만 레이블\n",
        "            # 정답 시작 위치 = 프롬프트 길이\n",
        "            prompt_len = len(ex[\"prompt_ids\"])\n",
        "            # (트렁케이션이 있었다면 prompt_len도 재계산이 필요하지만\n",
        "            # 위에서 뒤를 남겼으니 보통 prompt_len <= max_length를 만족)\n",
        "            labels = [-100] * len(ids)\n",
        "            for pos in range(prompt_len, len(ex[\"input_ids\"])):\n",
        "                if pos >= max_length:\n",
        "                    break\n",
        "                labels[pos] = ids[pos]\n",
        "\n",
        "            self.inputs.append(torch.tensor(ids))\n",
        "            self.attns.append(torch.tensor(attn))\n",
        "            self.labels.append(torch.tensor(labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.attns[idx], self.labels[idx]\n",
        "\n",
        "dataset = SFTDataset(qna_list, max_length=min(1024, max_length))\n",
        "loader  = DataLoader(dataset, batch_size=2, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTbJQvKDyXAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc792ba-c1c1-445d-8a5f-c6d838fa5119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 1792, padding_idx=128001)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1792, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1792, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1792, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1792, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1792, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1792, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=3072, out_features=1792, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1792, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1792, out_features=8064, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1792, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8064, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=1792, out_features=8064, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=1792, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8064, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=8064, out_features=1792, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8064, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1792, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((1792,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((1792,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((1792,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=1792, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "#device = \"cpu\"\n",
        "torch.manual_seed(123)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVnOWDPvya2y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f9deded-7cf9-4e51-e3c1-5998e3ce4ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q0: system\n",
            "\n",
            "You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's requestuser\n",
            "\n",
            "{\"user_request\": \"불교동아리\", \"task_plan\": \"좌측 메뉴에서 '학생신청(기타)'를 펼친다\", \"step_id\": \"1\", \"observations\": {\"sidebar\": [{\"id\": \"d7\", \"label\": \"학생신청(기타)\", \"expanded\": false}, {\"id\": \"e5\", \"label\": \"공지사항\", \"expanded\": true, \"sub_items\": [{\"id\": \"lq\", \"label\": \"공지사항조회\", \"checked\": true}]}]}}assistant\n",
            "\n",
            "### 현재 상태 및 계획:\n",
            "- **현재 좌측 메뉴 상태**: \"학생신청(기타)\"는 펼쳐져 있지 않음.\n",
            "- **현재 작업 계획**: 좌측 메뉴에서 '학생신청(기타)'를 펼친다.\n",
            "- **현재 관찰 상태**: \"학생신청(기타)\"는 펼쳐져 있지 않으며, \"공지사항조회\" 항목이 체크된 상태.\n",
            "\n",
            "### 단계별 실행 계획\n",
            "----------\n",
            "\n",
            "Q1: system\n",
            "\n",
            "You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's requestuser\n",
            "\n",
            "{\"user_request\": \"불교동아리 가입\", \"task_plan\": \"하위 메뉴 '불교동아리가입'을 클릭한다\", \"step_id\": \"2\", \"observations\": {\"sidebar\": [{\"id\": \"d7\", \"label\": \"학생신청(기타)\", \"expanded\": true, \"sub_items\": [{\"id\": \"ee\", \"label\": \"불교동아리가입\", \"checked\": false}]}]}}assistant\n",
            "\n",
            "### 현재 상태 및 계획:\n",
            "- **관찰 상태 (Observations)**:\n",
            "  - 왼쪽 메뉴: '학생신청(기타)' 항목이 확장된 상태이며, '불교동아리가입' 항목이 체크되지 않은 상태로 표시됨.\n",
            "- **작업 계획 (Task Plan)**: '불교동아리가입' 버튼을 클릭한다.\n",
            "- **현재 단계 (Step ID)**: 2\n",
            "\n",
            "### 실행\n",
            "----------\n",
            "\n",
            "Q2: system\n",
            "\n",
            "You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's requestuser\n",
            "\n",
            "{\"user_request\": \"불교동아리 가입하고싶어\", \"task_plan\": \"좌측 메뉴에서 '학생신청(기타)'를 펼친다\", \"step_id\": \"1\", \"observations\": {\"sidebar\": [{\"id\": \"d7\", \"label\": \"학생신청(기타)\", \"expanded\": false}, {\"id\": \"dq\", \"label\": \"성적\", \"expanded\": false}, {\"id\": \"ds\", \"label\": \"장학\", \"expanded\": false}]}}assistant\n",
            "\n",
            "### Observations\n",
            "- 현재 좌측 메뉴 상태: `학생신청(기타)`, `성적`, `장학` 항목이 펼쳐지지 않은 상태\n",
            "- 사용자가 요청한 작업: 불교동아리에 가입하고 싶음\n",
            "\n",
            "### Step-by-Step Plan\n",
            "1. **좌측 메뉴에서 '학생신청(기타)' 항목을 펼친다**:\n",
            "   - 현재 상태: `학생신청(기타)` 항목이 �\n",
            "----------\n",
            "\n",
            "Q3: system\n",
            "\n",
            "You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's requestuser\n",
            "\n",
            "{\"user_request\": \"불교동아리 어디서 가입해\", \"task_plan\": \"하위 메뉴 '불교동아리가입'을 클릭한다\", \"step_id\": \"2\", \"observations\": {\"sidebar\": [{\"id\": \"d7\", \"label\": \"학생신청(기타)\", \"expanded\": true, \"sub_items\": [{\"id\": \"ee\", \"label\": \"불교동아리가입\", \"checked\": false}]}]}}assistant\n",
            "\n",
            "### 현재 상태 및 계획:\n",
            "- **관찰 상태 (Observations)**:\n",
            "  - 왼쪽 메뉴: '학생신청(기타)' 항목이 확장된 상태이며, '불교동아리가입' 항목이 체크되지 않은 상태.\n",
            "- **단계 계획 (Task Plan)**: '불교동아리가입' 항목을 클릭한다.\n",
            "- **현재 단계 (Step ID)**: 2\n",
            "\n",
            "### 실행 계획:\n",
            "1\n",
            "----------\n",
            "\n",
            "Q4: system\n",
            "\n",
            "You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's requestuser\n",
            "\n",
            "{\"user_request\": \"불교동아리 가입 창 띄워줘\", \"task_plan\": \"좌측 메뉴에서 '학생신청(기타)'를 펼친다\", \"step_id\": \"1\", \"observations\": {\"sidebar\": [{\"id\": \"dy\", \"label\": \"졸업\", \"expanded\": false}, {\"id\": \"d7\", \"label\": \"학생신청(기타)\", \"expanded\": false}, {\"id\": \"dm\", \"label\": \"수강신청\", \"expanded\": false}]}}assistant\n",
            "\n",
            "### 현재 상태 및 계획:\n",
            "- **관찰 (Observations)**: 좌측 메뉴에서 '학생신청(기타)' 항목이 확장되지 않음.\n",
            "- **작업 계획 (Task Plan)**: 좌측 메뉴에서 '학생신청(기타)'를 펼친다.\n",
            "- **현재 단계 (Step ID)**: 1\n",
            "\n",
            "### 단계별 실행 계획:\n",
            "1. **좌측 메뉴 열기**: 사용자가 쉽게 접근할\n",
            "----------\n",
            "\n",
            "Q5: system\n",
            "\n",
            "You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's requestuser\n",
            "\n",
            "{\"user_request\": \"불교동아리가입할래\", \"task_plan\": \"하위 메뉴 '불교동아리가입'을 클릭한다\", \"step_id\": \"2\", \"observations\": {\"sidebar\": [{\"id\": \"d7\", \"label\": \"학생신청(기타)\", \"expanded\": true, \"sub_items\": [{\"id\": \"ee\", \"label\": \"불교동아리가입\", \"checked\": false}]}]}}assistant\n",
            "\n",
            "### 현재 상태 및 계획:\n",
            "- **관찰 상태 (Observations)**:\n",
            "  - 왼쪽 메뉴: '학생신청(기타)' 항목이 확장된 상태이며, '불교동아리가입' 항목이 체크되지 않은 상태.\n",
            "- **단계 번호 (Step ID)**: 2\n",
            "- **작업 계획 (Task Plan)**: '하위 메뉴 '불교동아리가입'을 클릭한다'\n",
            "- **\n",
            "----------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-795112857.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         output = model.generate(\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1971\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 459\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;31m# As per Tim Dettmers, for 4bit, we need to defensively clone here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;31m# The reason is that in some cases, an error can occur that backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py\u001b[0m in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMatMul4Bit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemv_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/functional.py\u001b[0m in \u001b[0;36mgemv_4bit\u001b[0;34m(A, B, out, transposed_A, transposed_B, state)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m     return torch.ops.bitsandbytes.gemv_4bit.default(\n\u001b[0m\u001b[1;32m   1538\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;31m# that are named \"self\". This way, all the aten ops can be called by kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;31m# Use positional-only argument to avoid naming collision with aten ops arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# cache this on the first invocation to avoid adding too much overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 파인튜닝 전에 어떻게 대답하는지 확인\n",
        "questions = [ qna['q_ids'] for qna in qna_list]\n",
        "\n",
        "for i, q_ids in enumerate(questions):\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            torch.tensor([q_ids]).to(\"cuda\"),\n",
        "            max_new_tokens=100,\n",
        "            #attention_mask = (input_ids != 0).long(),\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=False,\n",
        "            # temperature=1.2,\n",
        "            # top_k=5\n",
        "        )\n",
        "\n",
        "    output_list = output.tolist()\n",
        "\n",
        "    print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")\n",
        "    print(\"----------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhkXO35k-AFZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZKK9p69zoBk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "59de90a5-fd86-4fec-8fe7-66efa5f23a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_000\n",
            "epoch 1 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_001\n",
            "epoch 2 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_002\n",
            "epoch 3 | loss 0.0903\n",
            "[saved] LoRA adapter -> ./adapters/epoch_003\n",
            "epoch 4 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_004\n",
            "epoch 5 | loss 0.0726\n",
            "[saved] LoRA adapter -> ./adapters/epoch_005\n",
            "epoch 6 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_006\n",
            "epoch 7 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_007\n",
            "epoch 8 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_008\n",
            "epoch 9 | loss nan\n",
            "[saved] LoRA adapter -> ./adapters/epoch_009\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/loss_epoch</td><td>   █ ▁    </td></tr><tr><td>train/loss_step</td><td>▄ ▄▄▂▁▁▁▁ ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁ ▂   ▁▁█▄▂ </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>step</td><td>80</td></tr><tr><td>train/loss_epoch</td><td>nan</td></tr><tr><td>train/loss_step</td><td>nan</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">graceful-jazz-9</strong> at: <a href='https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2/runs/ltxu9fsh?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab' target=\"_blank\">https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2/runs/ltxu9fsh?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab</a><br> View project at: <a href='https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab' target=\"_blank\">https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251121_021039-ltxu9fsh/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "losses = []\n",
        "\n",
        "global_step = 0\n",
        "\n",
        "model.train()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "    total = 0.0\n",
        "    for input_ids, attn_mask, labels in loader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        attn_mask = attn_mask.to(device)\n",
        "        labels    = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(input_ids=input_ids, attention_mask=attn_mask, labels=labels)\n",
        "        loss = out.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "\n",
        "        global_step += 1\n",
        "\n",
        "        wandb.log({\n",
        "            \"train/loss_step\": loss.item(),\n",
        "            \"epoch\": epoch,\n",
        "            \"step\": global_step,\n",
        "        })\n",
        "\n",
        "    avg_loss = total / len(loader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"epoch {epoch} | loss {avg_loss:.4f}\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"train/loss_epoch\": avg_loss,\n",
        "        \"epoch\": epoch,\n",
        "    })\n",
        "\n",
        "    # ★ LoRA 어댑터 저장 (중요)\n",
        "    save_dir = f\"./adapters/epoch_{epoch:03d}\"\n",
        "    model.save_pretrained(save_dir)      # ← 어댑터 가중치 저장\n",
        "    # (선택) 토크나이저도 함께 보관하면 편함\n",
        "    tokenizer.save_pretrained(save_dir)\n",
        "    print(f\"[saved] LoRA adapter -> {save_dir}\")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame, display\n",
        "\n",
        "\n",
        "display(IFrame(run.url, width=1200, height=720))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "lc2pjKL2mDa_",
        "outputId": "90bfac26-165f-4f14-95bf-2cb65523cf0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f9c483d3560>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1200\"\n",
              "            height=\"720\"\n",
              "            src=\"https://wandb.ai/hello03085-dongguk-university/Fine%20tuning%20%20LAM2/runs/fegtjpdk?apiKey=9ed675d942c745bf3fdf524bba1fcd137e6e81ab\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt1lBgeZLopX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f02b11-251d-44a8-edf3-a355626024c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 로드 완료\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "base_repo = \"leeChaerin/PlanModel_v1\"\n",
        "adapter_path = \"./adapters/epoch_009\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_repo)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_repo,\n",
        "    torch_dtype=torch.float16,   # 또는 float32 (CPU면)\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "model.eval()\n",
        "\n",
        "print(\"모델 로드 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxJ5ujNzPV7i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "7769173f-0bd1-4a1c-a032-3cbb7f64d06d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGJCAYAAACQKdlyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUVtJREFUeJzt3XtYVNX+P/D3cJthFLyhjKiBt0S8oGIimmKFgFFGGpJZIqkcDfLC0QqPicjPKO+mpGmCesxASlHTCOREVmDmBRNT0/JSyYBmiooCwfr94Zc57WYGEAeHPef9ep55njNrr732+uyZfXy3L4NCCCFAREREJENW5p4AERERUX0xyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEMnMhAkT4ObmVq9158+fD4VCYdoJEdWi+nt35coVc0+FLBCDDJGJKBSKOr1ycnLMPVWzmDBhApo2bWruadSJEAL//ve/MXToUDRv3hxqtRq9evXCggULcOvWLXNPT091UDD20mq15p4iUYOxMfcEiCzFv//9b8n7zZs3IysrS6+9e/fu97Wd9evXo6qqql7rzp07F2+88cZ9bd/SVVZW4oUXXsC2bdswZMgQzJ8/H2q1Gl999RXi4uKQlpaGffv2wdnZ2dxT1bNmzRqDYbF58+YPfjJEDwiDDJGJvPjii5L3Bw4cQFZWll7735WWlkKtVtd5O7a2tvWaHwDY2NjAxoaHfU0WLVqEbdu2YdasWVi8eLGuPSIiAmPGjEFwcDAmTJiAzz777IHOqy7fk+eeew5OTk4PaEZEjQMvLRE9QMOGDUPPnj1x+PBhDB06FGq1GnPmzAEA7Ny5E0FBQXBxcYFSqUTnzp0RHx+PyspKyRh/v0fm/PnzUCgUWLJkCdatW4fOnTtDqVTikUcewXfffSdZ19A9MgqFAlFRUUhPT0fPnj2hVCrRo0cPZGRk6M0/JycH/fv3h0qlQufOnfH++++b/L6btLQ0eHl5wd7eHk5OTnjxxRfx22+/SfpotVqEh4ejffv2UCqVaNu2LZ555hmcP39e1+fQoUMICAiAk5MT7O3t0bFjR7z88ss1bvv27dtYvHgxHn74YSQkJOgtf/rppxEWFoaMjAwcOHAAAPDUU0+hU6dOBsfz8fFB//79JW1btmzR1deyZUs8//zz+OWXXyR9avqe3I+cnBwoFAqkpqZizpw50Gg0aNKkCUaOHKk3B6BunwUAnDp1CmPGjEHr1q1hb2+Pbt264V//+pdev2vXrmHChAlo3rw5mjVrhvDwcJSWlkr6ZGVl4dFHH0Xz5s3RtGlTdOvWzSS1k+Xif5oRPWC///47RowYgeeffx4vvvii7hLFxo0b0bRpU0RHR6Np06b4z3/+g3nz5qGkpERyZsCYrVu34saNG/jHP/4BhUKBRYsWYdSoUfj5559rPYvz9ddfY/v27XjllVfg4OCAd999F6NHj8bFixfRqlUrAMDRo0cRGBiItm3bIi4uDpWVlViwYAFat259/zvl/2zcuBHh4eF45JFHkJCQgKKiIqxcuRLffPMNjh49qrtEMnr0aJw4cQKvvvoq3NzcUFxcjKysLFy8eFH33t/fH61bt8Ybb7yB5s2b4/z589i+fXut++GPP/7A9OnTjZ65Gj9+PJKTk/Hpp59i4MCBCA0Nxfjx4/Hdd9/hkUce0fW7cOECDhw4IPnsFi5ciDfffBNjxozBpEmTcPnyZaxatQpDhw6V1AcY/57U5OrVq3ptNjY2epeWFi5cCIVCgddffx3FxcVYsWIF/Pz8kJ+fD3t7ewB1/yy+//57DBkyBLa2toiIiICbmxt++ukn7N69GwsXLpRsd8yYMejYsSMSEhJw5MgRfPDBB2jTpg3eeecdAMCJEyfw1FNPoXfv3liwYAGUSiXOnj2Lb775ptba6X+YIKIGERkZKf5+iPn6+goAYu3atXr9S0tL9dr+8Y9/CLVaLe7cuaNrCwsLE66urrr3586dEwBEq1atxNWrV3XtO3fuFADE7t27dW2xsbF6cwIg7OzsxNmzZ3Vtx44dEwDEqlWrdG1PP/20UKvV4rffftO1nTlzRtjY2OiNaUhYWJho0qSJ0eXl5eWiTZs2omfPnuL27du69k8//VQAEPPmzRNCCPHHH38IAGLx4sVGx9qxY4cAIL777rta5/VXK1asEADEjh07jPa5evWqACBGjRolhBDi+vXrQqlUin/+85+SfosWLRIKhUJcuHBBCCHE+fPnhbW1tVi4cKGk3/Hjx4WNjY2kvabviSHVn6uhV7du3XT9vvjiCwFAtGvXTpSUlOjat23bJgCIlStXCiHq/lkIIcTQoUOFg4ODrs5qVVVVevN7+eWXJX2effZZ0apVK9375cuXCwDi8uXLdaqbSAgheGmJ6AFTKpUIDw/Xa6/+L2EAuHHjBq5cuYIhQ4agtLQUp06dqnXc0NBQtGjRQvd+yJAhAICff/651nX9/PzQuXNn3fvevXvD0dFRt25lZSX27duH4OBguLi46Pp16dIFI0aMqHX8ujh06BCKi4vxyiuvQKVS6dqDgoLg7u6OPXv2ALi7n+zs7JCTk4M//vjD4FjVZws+/fRTVFRU1HkON27cAAA4ODgY7VO9rKSkBADg6OiIESNGYNu2bRBC6PqlpqZi4MCBeOihhwAA27dvR1VVFcaMGYMrV67oXhqNBl27dsUXX3wh2Y6x70lNPvnkE2RlZUleycnJev3Gjx8vqfG5555D27ZtsXfvXgB1/ywuX76M/fv34+WXX9bVWc3Q5cYpU6ZI3g8ZMgS///67bl9Wf247d+6s9w3t9L+HQYboAWvXrh3s7Oz02k+cOIFnn30WzZo1g6OjI1q3bq27Ufj69eu1jvv3f0iqQ42xf+xrWrd6/ep1i4uLcfv2bXTp0kWvn6G2+rhw4QIAoFu3bnrL3N3ddcuVSiXeeecdfPbZZ3B2dsbQoUOxaNEiySPGvr6+GD16NOLi4uDk5IRnnnkGycnJKCsrq3EO1f+4VwcaQwyFndDQUPzyyy/Iy8sDAPz00084fPgwQkNDdX3OnDkDIQS6du2K1q1bS14nT55EcXGxZDvGvic1GTp0KPz8/CQvHx8fvX5du3aVvFcoFOjSpYvuHqO6fhbVQbdnz551ml9t39HQ0FAMHjwYkyZNgrOzM55//nls27aNoYZqxCBD9ID99cxLtWvXrsHX1xfHjh3DggULsHv3bmRlZenuHajL/5FbW1sbbP/rWYKGWNccZsyYgR9//BEJCQlQqVR488030b17dxw9ehTA3X+YP/74Y+Tl5SEqKgq//fYbXn75ZXh5eeHmzZtGx61+NP7777832qd6mYeHh67t6aefhlqtxrZt2wAA27Ztg5WVFUJCQnR9qqqqoFAokJGRoXfWJCsrC++//75kO4a+J3JX2/fM3t4e+/fvx759+/DSSy/h+++/R2hoKIYPH6530ztRNQYZokYgJycHv//+OzZu3Ijp06fjqaeegp+fn+RSkTm1adMGKpUKZ8+e1VtmqK0+XF1dAQCnT5/WW3b69Gnd8mqdO3fGP//5T2RmZqKgoADl5eVYunSppM/AgQOxcOFCHDp0CB9++CFOnDiBlJQUo3Ooflpm69atRv/h3Lx5M4C7TytVa9KkCZ566imkpaWhqqoKqampGDJkiOQyXOfOnSGEQMeOHfXOmvj5+WHgwIG17CHTOXPmjOS9EAJnz57VPQ1X18+i+mmtgoICk83NysoKTzzxBJYtW4YffvgBCxcuxH/+8x+9S29E1RhkiBqB6v9S/esZkPLycrz33nvmmpKEtbU1/Pz8kJ6ejkuXLunaz549a7LfU+nfvz/atGmDtWvXSi4BffbZZzh58iSCgoIA3P09lTt37kjW7dy5MxwcHHTr/fHHH3pnk/r06QMANV5eUqvVmDVrFk6fPm3w8eE9e/Zg48aNCAgI0AseoaGhuHTpEj744AMcO3ZMclkJAEaNGgVra2vExcXpzU0Igd9//93ovExt8+bNkstnH3/8MQoLC3X3O9X1s2jdujWGDh2KpKQkXLx4UbKN+pzNM/TUVV0+N/rfxseviRqBQYMGoUWLFggLC8O0adOgUCjw73//u1Fd2pk/fz4yMzMxePBgTJ06FZWVlVi9ejV69uyJ/Pz8Oo1RUVGB//f//p9ee8uWLfHKK6/gnXfeQXh4OHx9fTF27FjdI79ubm6YOXMmAODHH3/EE088gTFjxsDDwwM2NjbYsWMHioqK8PzzzwMANm3ahPfeew/PPvssOnfujBs3bmD9+vVwdHTEk08+WeMc33jjDRw9ehTvvPMO8vLyMHr0aNjb2+Prr7/Gli1b0L17d2zatElvvSeffBIODg6YNWsWrK2tMXr0aMnyzp074//9v/+HmJgYnD9/HsHBwXBwcMC5c+ewY8cOREREYNasWXXaj8Z8/PHHBn/Zd/jw4ZLHt1u2bIlHH30U4eHhKCoqwooVK9ClSxdMnjwZwN0fXazLZwEA7777Lh599FH069cPERER6NixI86fP489e/bU+XtRbcGCBdi/fz+CgoLg6uqK4uJivPfee2jfvj0effTR+u0UsnxmeVaK6H+Asceve/ToYbD/N998IwYOHCjs7e2Fi4uLeO2118Tnn38uAIgvvvhC18/Y49eGHkcGIGJjY3XvjT1+HRkZqbeuq6urCAsLk7RlZ2eLvn37Cjs7O9G5c2fxwQcfiH/+859CpVIZ2Qv/FRYWZvQR4c6dO+v6paamir59+wqlUilatmwpxo0bJ3799Vfd8itXrojIyEjh7u4umjRpIpo1aya8vb3Ftm3bdH2OHDkixo4dKx566CGhVCpFmzZtxFNPPSUOHTpU6zyFEKKyslIkJyeLwYMHC0dHR6FSqUSPHj1EXFycuHnzptH1xo0bJwAIPz8/o30++eQT8eijj4omTZqIJk2aCHd3dxEZGSlOnz6t61PT98SQmh6//uv3p/rx648++kjExMSINm3aCHt7exEUFKT3+LQQtX8W1QoKCsSzzz4rmjdvLlQqlejWrZt488039eb398eqk5OTBQBx7tw5IcTd79czzzwjXFxchJ2dnXBxcRFjx44VP/74Y533Bf3vUQjRiP6Tj4hkJzg4GCdOnNC774Ian5ycHDz22GNIS0vDc889Z+7pEJkE75Ehojq7ffu25P2ZM2ewd+9eDBs2zDwTIqL/ebxHhojqrFOnTpgwYQI6deqECxcuYM2aNbCzs8Nrr71m7qkR0f8oBhkiqrPAwEB89NFH0Gq1UCqV8PHxwVtvvaX3A2tERA8K75EhIiIi2eI9MkRERCRbDDJEREQkW7xHpgFVVVXh0qVLcHBwMPiXYImIiMgwIQRu3LgBFxcXWFkZP+/CINOALl26hA4dOph7GkRERLL1yy+/oH379kaXM8g0IAcHBwB3PwRHR0eTjFlRUYHMzEz4+/vD1tbWJGOam6XVZGn1AKxJLliTPFhaTQ1VT0lJCTp06KD7t9QYBpkGVH05ydHR0aRBRq1Ww9HR0SIOAMDyarK0egDWJBesSR4sraaGrqe2WzN4sy8RERHJFoMMERERyRaDDBEREckWgwwRERHJFoMMERERyRaDDBEREckWg4yMVFYJfHvuKg5fUeDbc1dRWcW/90lERP/b+DsyMpFRUIi43T+g8PodANbYfOYQ2jZTIfZpDwT2bGvu6REREZkFz8jIQEZBIaZuOfJ/Iea/tNfvYOqWI8goKDTTzIiIiMyLQaaRq6wSiNv9AwxdRKpui9v9Ay8zERHR/yQGmUbu4Lmremdi/koAKLx+BwfPXX1wkyIiImokzB5kEhMT4ebmBpVKBW9vbxw8eLDG/mlpaXB3d4dKpUKvXr2wd+9eyfKioiJMmDABLi4uUKvVCAwMxJkzZyR97ty5g8jISLRq1QpNmzbF6NGjUVRUJOlz8eJFBAUFQa1Wo02bNpg9ezb+/PNP0xR9D4pvGA8x9elHRERkScwaZFJTUxEdHY3Y2FgcOXIEnp6eCAgIQHFxscH+ubm5GDt2LCZOnIijR48iODgYwcHBKCgoAAAIIRAcHIyff/4ZO3fuxNGjR+Hq6go/Pz/cunVLN87MmTOxe/dupKWl4csvv8SlS5cwatQo3fLKykoEBQWhvLwcubm52LRpEzZu3Ih58+Y17A4xoI2DyqT9iIiILIlZg8yyZcswefJkhIeHw8PDA2vXroVarUZSUpLB/itXrkRgYCBmz56N7t27Iz4+Hv369cPq1asBAGfOnMGBAwewZs0aPPLII+jWrRvWrFmD27dv46OPPgIAXL9+HRs2bMCyZcvw+OOPw8vLC8nJycjNzcWBAwcAAJmZmfjhhx+wZcsW9OnTByNGjEB8fDwSExNRXl7+YHbO/xnQsSXaNlPB2N/+VABo20yFAR1bPshpERERNQpme/y6vLwchw8fRkxMjK7NysoKfn5+yMvLM7hOXl4eoqOjJW0BAQFIT08HAJSVlQEAVKr/np2wsrKCUqnE119/jUmTJuHw4cOoqKiAn5+fro+7uzseeugh5OXlYeDAgcjLy0OvXr3g7Ows2c7UqVNx4sQJ9O3b1+D8ysrKdHMAgJKSEgB3/8R5RUVFXXaLQf8a0Q2vphyDApDc9Kv4y/Kqyj9RVVnvTZhV9b65n33UmFhaPQBrkgvWJA+WVlND1VPX8cwWZK5cuYLKykpJWAAAZ2dnnDp1yuA6Wq3WYH+tVgvgv4EkJiYG77//Ppo0aYLly5fj119/RWFhoW4MOzs7NG/e3Og4xrZTvcyYhIQExMXF6bVnZmZCrVYbXa8uwh9WYPt5K1wr/++5mWZ2AqPcqlB54TD2Xriv4RuFrKwsc0/BpCytHoA1yQVrkgdLq8nU9ZSWltapn0X9IJ6trS22b9+OiRMnomXLlrC2toafnx9GjBgBIRr+8eSYmBjJGaOSkhJ06NAB/v7+cHR0vK+xnwTwWpXAgZ8u4z95h/G4jxcGdm4NaytjF53ko6KiAllZWRg+fDhsbW3NPZ37Zmn1AKxJLliTPFhaTQ1VT/VVjdqYLcg4OTnB2tpa72mhoqIiaDQag+toNJpa+3t5eSE/Px/Xr19HeXk5WrduDW9vb/Tv3183Rnl5Oa5duyY5K/PXcTQajd7TU9XbNTY3AFAqlVAqlXrttra2JvlwbQEM7toG188IDO7axiIOgL8y1X5qLCytHoA1yQVrkgdLq8nU9dR1LLPd7GtnZwcvLy9kZ2fr2qqqqpCdnQ0fHx+D6/j4+Ej6A3dPZRnq36xZM7Ru3RpnzpzBoUOH8MwzzwC4G3RsbW0l45w+fRoXL17UjePj44Pjx49Lnp7KysqCo6MjPDw86l80ERERmZRZLy1FR0cjLCwM/fv3x4ABA7BixQrcunUL4eHhAIDx48ejXbt2SEhIAABMnz4dvr6+WLp0KYKCgpCSkoJDhw5h3bp1ujHT0tLQunVrPPTQQzh+/DimT5+O4OBg+Pv7A7gbcCZOnIjo6Gi0bNkSjo6OePXVV+Hj44OBAwcCAPz9/eHh4YGXXnoJixYtglarxdy5cxEZGWnwjAsRERGZh1mDTGhoKC5fvox58+ZBq9WiT58+yMjI0N1Ye/HiRVhZ/fek0aBBg7B161bMnTsXc+bMQdeuXZGeno6ePXvq+hQWFiI6OhpFRUVo27Ytxo8fjzfffFOy3eXLl8PKygqjR49GWVkZAgIC8N577+mWW1tb49NPP8XUqVPh4+ODJk2aICwsDAsWLGjgPUJERET3wuw3+0ZFRSEqKsrgspycHL22kJAQhISEGB1v2rRpmDZtWo3bVKlUSExMRGJiotE+rq6uer8aTERERI2L2f9EAREREVF9McgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWwxyBAREZFsMcgQERGRbJk9yCQmJsLNzQ0qlQre3t44ePBgjf3T0tLg7u4OlUqFXr16Ye/evZLlN2/eRFRUFNq3bw97e3t4eHhg7dq1uuXnz5+HQqEw+EpLS9P1M7Q8JSXFtMUTERHRfTFrkElNTUV0dDRiY2Nx5MgReHp6IiAgAMXFxQb75+bmYuzYsZg4cSKOHj2K4OBgBAcHo6CgQNcnOjoaGRkZ2LJlC06ePIkZM2YgKioKu3btAgB06NABhYWFkldcXByaNm2KESNGSLaXnJws6RccHNxg+4KIiIjunVmDzLJlyzB58mSEh4frzpyo1WokJSUZ7L9y5UoEBgZi9uzZ6N69O+Lj49GvXz+sXr1a1yc3NxdhYWEYNmwY3NzcEBERAU9PT92ZHmtra2g0Gslrx44dGDNmDJo2bSrZXvPmzSX9VCpVw+0MIiIiumc25tpweXk5Dh8+jJiYGF2blZUV/Pz8kJeXZ3CdvLw8REdHS9oCAgKQnp6uez9o0CDs2rULL7/8MlxcXJCTk4Mff/wRy5cvNzjm4cOHkZ+fj8TERL1lkZGRmDRpEjp16oQpU6YgPDwcCoXCaE1lZWUoKyvTvS8pKQEAVFRUoKKiwuh696J6HFON1xhYWk2WVg/AmuSCNcmDpdXUUPXUdTyzBZkrV66gsrISzs7OknZnZ2ecOnXK4DpardZgf61Wq3u/atUqREREoH379rCxsYGVlRXWr1+PoUOHGhxzw4YN6N69OwYNGiRpX7BgAR5//HGo1WpkZmbilVdewc2bNzFt2jSjNSUkJCAuLk6vPTMzE2q12uh69ZGVlWXS8RoDS6vJ0uoBWJNcsCZ5sLSaTF1PaWlpnfqZLcg0lFWrVuHAgQPYtWsXXF1dsX//fkRGRsLFxQV+fn6Svrdv38bWrVvx5ptv6o3z17a+ffvi1q1bWLx4cY1BJiYmRnLGqKSkBB06dIC/vz8cHR1NUN3dhJqVlYXhw4fD1tbWJGOam6XVZGn1AKxJLliTPFhaTQ1VT/VVjdqYLcg4OTnB2toaRUVFkvaioiJoNBqD62g0mhr73759G3PmzMGOHTsQFBQEAOjduzfy8/OxZMkSvSDz8ccfo7S0FOPHj691vt7e3oiPj0dZWRmUSqXBPkql0uAyW1tbk39ZG2JMc7O0miytHoA1yQVrkgdLq8nU9dR1LLPd7GtnZwcvLy9kZ2fr2qqqqpCdnQ0fHx+D6/j4+Ej6A3dPZVX3r74XxcpKWpa1tTWqqqr0xtuwYQNGjhyJ1q1b1zrf/Px8tGjRwmiIISIiogfPrJeWoqOjERYWhv79+2PAgAFYsWIFbt26hfDwcADA+PHj0a5dOyQkJAAApk+fDl9fXyxduhRBQUFISUnBoUOHsG7dOgCAo6MjfH19MXv2bNjb28PV1RVffvklNm/ejGXLlkm2ffbsWezfv1/vd2gAYPfu3SgqKsLAgQOhUqmQlZWFt956C7NmzWrgPUJERET3wqxBJjQ0FJcvX8a8efOg1WrRp08fZGRk6G7ovXjxouTsyqBBg7B161bMnTsXc+bMQdeuXZGeno6ePXvq+qSkpCAmJgbjxo3D1atX4erqioULF2LKlCmSbSclJaF9+/bw9/fXm5etrS0SExMxc+ZMCCHQpUsX3aPiRERE1HiY/WbfqKgoREVFGVyWk5Oj1xYSEoKQkBCj42k0GiQnJ9e63bfeegtvvfWWwWWBgYEIDAysdQwiIiIyL7P/iQIiIiKi+mKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItkye5BJTEyEm5sbVCoVvL29cfDgwRr7p6Wlwd3dHSqVCr169cLevXsly2/evImoqCi0b98e9vb28PDwwNq1ayV9hg0bBoVCIXlNmTJF0ufixYsICgqCWq1GmzZtMHv2bPz555+mKZqIiIhMwqxBJjU1FdHR0YiNjcWRI0fg6emJgIAAFBcXG+yfm5uLsWPHYuLEiTh69CiCg4MRHByMgoICXZ/o6GhkZGRgy5YtOHnyJGbMmIGoqCjs2rVLMtbkyZNRWFioey1atEi3rLKyEkFBQSgvL0dubi42bdqEjRs3Yt68eQ2zI4iIiKhebMy58WXLlmHy5MkIDw8HAKxduxZ79uxBUlIS3njjDb3+K1euRGBgIGbPng0AiI+PR1ZWFlavXq0765Kbm4uwsDAMGzYMABAREYH3338fBw8exMiRI3VjqdVqaDQag/PKzMzEDz/8gH379sHZ2Rl9+vRBfHw8Xn/9dcyfPx92dnYG1ysrK0NZWZnufUlJCQCgoqICFRUV97h3DKsex1TjNQaWVpOl1QOwJrlgTfJgaTU1VD11HU8hhBAm3XIdlZeXQ61W4+OPP0ZwcLCuPSwsDNeuXcPOnTv11nnooYcQHR2NGTNm6NpiY2ORnp6OY8eOAbgbXI4ePYr09HS4uLggJycHI0eOxJ49ezB06FAAdy8tnThxAkIIaDQaPP3003jzzTehVqsBAPPmzcOuXbuQn5+v2865c+fQqVMnHDlyBH379jVY0/z58xEXF6fXvnXrVt3YREREVLvS0lK88MILuH79OhwdHY32M9sZmStXrqCyshLOzs6SdmdnZ5w6dcrgOlqt1mB/rVare79q1SpERESgffv2sLGxgZWVFdavX68LMQDwwgsvwNXVFS4uLvj+++/x+uuv4/Tp09i+fXuN26leZkxMTAyio6N170tKStChQwf4+/vX+CHci4qKCmRlZWH48OGwtbU1yZjmZmk1WVo9AGuSC9YkD5ZWU0PVU31VozZmvbTUEFatWoUDBw5g165dcHV1xf79+xEZGQkXFxf4+fkBuHvWplqvXr3Qtm1bPPHEE/jpp5/QuXPnem9bqVRCqVTqtdva2pr8y9oQY5qbpdVkafUArEkuWJM8WFpNpq6nrmOZLcg4OTnB2toaRUVFkvaioiKj965oNJoa+9++fRtz5szBjh07EBQUBADo3bs38vPzsWTJEl2Q+Ttvb28AwNmzZ9G5c2doNBq9p6eqt2tsbkRERPTgme2pJTs7O3h5eSE7O1vXVlVVhezsbPj4+Bhcx8fHR9IfALKysnT9q2+qtbKSlmVtbY2qqiqjc6m+F6Zt27a67Rw/flzy9FRWVhYcHR3h4eFR9yKJiIioQZn10lJ0dDTCwsLQv39/DBgwACtWrMCtW7d0TzGNHz8e7dq1Q0JCAgBg+vTp8PX1xdKlSxEUFISUlBQcOnQI69atAwA4OjrC19cXs2fPhr29PVxdXfHll19i8+bNWLZsGQDgp59+wtatW/Hkk0+iVatW+P777zFz5kwMHToUvXv3BgD4+/vDw8MDL730EhYtWgStVou5c+ciMjLS4KUjIiIiMg+zBpnQ0FBcvnwZ8+bNg1arRZ8+fZCRkaG7sfbixYuSsyuDBg3C1q1bMXfuXMyZMwddu3ZFeno6evbsqeuTkpKCmJgYjBs3DlevXoWrqysWLlyo+8E7Ozs77Nu3TxeaOnTogNGjR2Pu3Lm6MaytrfHpp59i6tSp8PHxQZMmTRAWFoYFCxY8oD1DREREdWH2m32joqIQFRVlcFlOTo5eW0hICEJCQoyOp9FokJycbHR5hw4d8OWXX9Y6L1dXV71fDSYiIqLGxex/ooCIiIiovhhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhItsweZBITE+Hm5gaVSgVvb28cPHiwxv5paWlwd3eHSqVCr169sHfvXsnymzdvIioqCu3bt4e9vT08PDywdu1a3fKrV6/i1VdfRbdu3WBvb4+HHnoI06ZNw/Xr1yXjKBQKvVdKSorpCiciIqL7ZtYgk5qaiujoaMTGxuLIkSPw9PREQEAAiouLDfbPzc3F2LFjMXHiRBw9ehTBwcEIDg5GQUGBrk90dDQyMjKwZcsWnDx5EjNmzEBUVBR27doFALh06RIuXbqEJUuWoKCgABs3bkRGRgYmTpyot73k5GQUFhbqXsHBwQ2yH4iIiKh+zBpkli1bhsmTJyM8PFx35kStViMpKclg/5UrVyIwMBCzZ89G9+7dER8fj379+mH16tW6Prm5uQgLC8OwYcPg5uaGiIgIeHp66s709OzZE5988gmefvppdO7cGY8//jgWLlyI3bt3488//5Rsr3nz5tBoNLqXSqVquJ1BRERE98zGXBsuLy/H4cOHERMTo2uzsrKCn58f8vLyDK6Tl5eH6OhoSVtAQADS09N17wcNGoRdu3bh5ZdfhouLC3JycvDjjz9i+fLlRudy/fp1ODo6wsZGujsiIyMxadIkdOrUCVOmTEF4eDgUCoXRccrKylBWVqZ7X1JSAgCoqKhARUWF0fXuRfU4phqvMbC0miytHoA1yQVrkgdLq6mh6qnreGYLMleuXEFlZSWcnZ0l7c7Ozjh16pTBdbRarcH+Wq1W937VqlWIiIhA+/btYWNjAysrK6xfvx5Dhw41Oo/4+HhERERI2hcsWIDHH38carUamZmZeOWVV3Dz5k1MmzbNaE0JCQmIi4vTa8/MzIRarTa6Xn1kZWWZdLzGwNJqsrR6ANYkF6xJHiytJlPXU1paWqd+ZgsyDWXVqlU4cOAAdu3aBVdXV+zfvx+RkZFwcXGBn5+fpG9JSQmCgoLg4eGB+fPnS5a9+eabuv/dt29f3Lp1C4sXL64xyMTExEjOGJWUlKBDhw7w9/eHo6OjSeqrqKhAVlYWhg8fDltbW5OMaW6WVpOl1QOwJrlgTfJgaTU1VD3VVzVqY7Yg4+TkBGtraxQVFUnai4qKoNFoDK6j0Whq7H/79m3MmTMHO3bsQFBQEACgd+/eyM/Px5IlSyRB5saNGwgMDISDgwN27NhR68739vZGfHw8ysrKoFQqDfZRKpUGl9na2pr8y9oQY5qbpdVkafUArEkuWJM8WFpNpq6nrmOZ7WZfOzs7eHl5ITs7W9dWVVWF7Oxs+Pj4GFzHx8dH0h+4eyqrun/1vShWVtKyrK2tUVVVpXtfUlICf39/2NnZYdeuXXW6iTc/Px8tWrQwGmKIiIjowTPrpaXo6GiEhYWhf//+GDBgAFasWIFbt24hPDwcADB+/Hi0a9cOCQkJAIDp06fD19cXS5cuRVBQEFJSUnDo0CGsW7cOAODo6AhfX1/Mnj0b9vb2cHV1xZdffonNmzdj2bJlAP4bYkpLS7FlyxaUlJToTl+1bt0a1tbW2L17N4qKijBw4ECoVCpkZWXhrbfewqxZs8ywl4iIiMiYegWZX375BQqFAu3btwcAHDx4EFu3boWHh4feTbM1CQ0NxeXLlzFv3jxotVr06dMHGRkZuht6L168KDm7MmjQIGzduhVz587FnDlz0LVrV6Snp6Nnz566PikpKYiJicG4ceNw9epVuLq6YuHChZgyZQoA4MiRI/j2228BAF26dJHM59y5c3Bzc4OtrS0SExMxc+ZMCCHQpUsX3aPiRERE1HjUK8i88MILiIiIwEsvvQStVovhw4ejR48e+PDDD6HVajFv3rw6jxUVFYWoqCiDy3JycvTaQkJCEBISYnQ8jUaD5ORko8uHDRsGIUSNcwoMDERgYGCNfYiIiMj86nWPTEFBAQYMGAAA2LZtG3r27Inc3Fx8+OGH2LhxoynnR0RERGRUvYJMRUWF7qbXffv2YeTIkQAAd3d3FBYWmm52RERERDWoV5Dp0aMH1q5di6+++gpZWVm6yzCXLl1Cq1atTDpBIiIiImPqFWTeeecdvP/++xg2bBjGjh0LT09PAMCuXbt0l5yIiIiIGlq9bvYdNmwYrly5gpKSErRo0ULXHhERYfKf4iciIiIypl5nZG7fvo2ysjJdiLlw4QJWrFiB06dPo02bNiadIBEREZEx9QoyzzzzDDZv3gwAuHbtGry9vbF06VIEBwdjzZo1Jp0gERERkTH1CjJHjhzBkCFDAAAff/wxnJ2dceHCBWzevBnvvvuuSSdIREREZEy9gkxpaSkcHBwAAJmZmRg1ahSsrKwwcOBAXLhwwaQTJCIiIjKmXkGmS5cuSE9Pxy+//ILPP/8c/v7+AIDi4mI4OjqadIJERERExtQryMybNw+zZs2Cm5sbBgwYoPvr05mZmejbt69JJ0hERERkTL0ev37uuefw6KOPorCwUPcbMgDwxBNP4NlnnzXZ5IiIiIhqUq8gA9z944wajQa//vorAKB9+/b8MTwiIiJ6oOp1aamqqgoLFixAs2bN4OrqCldXVzRv3hzx8fGoqqoy9RyJiIiIDKrXGZl//etf2LBhA95++20MHjwYAPD1119j/vz5uHPnDhYuXGjSSRIREREZUq8gs2nTJnzwwQe6v3oNAL1790a7du3wyiuvMMgQERHRA1GvS0tXr16Fu7u7Xru7uzuuXr1635MiIiIiqot6BRlPT0+sXr1ar3316tXo3bv3fU+KiIiIqC7qdWlp0aJFCAoKwr59+3S/IZOXl4dffvkFe/fuNekEiYiIiIyp1xkZX19f/Pjjj3j22Wdx7do1XLt2DaNGjcKJEyfw73//29RzJCIiIjKo3r8j4+LiondT77Fjx7BhwwasW7fuvidGREREVJt6nZEhIiIiagwYZIiIiEi2GGSIiIhItu7pHplRo0bVuPzatWv3MxciIiKie3JPQaZZs2a1Lh8/fvx9TYiIiIioru4pyCQnJzfUPIiIiIjuGe+RISIiItlikCEiIiLZMnuQSUxMhJubG1QqFby9vXHw4MEa+6elpcHd3R0qlQq9evXS+5MIN2/eRFRUFNq3bw97e3t4eHhg7dq1kj537txBZGQkWrVqhaZNm2L06NEoKiqS9Ll48SKCgoKgVqvRpk0bzJ49G3/++adpiiYiIiKTMGuQSU1NRXR0NGJjY3HkyBF4enoiICAAxcXFBvvn5uZi7NixmDhxIo4ePYrg4GAEBwejoKBA1yc6OhoZGRnYsmULTp48iRkzZiAqKgq7du3S9Zk5cyZ2796NtLQ0fPnll7h06ZLkiazKykoEBQWhvLwcubm52LRpEzZu3Ih58+Y13M4gIiKie2bWILNs2TJMnjwZ4eHhujMnarUaSUlJBvuvXLkSgYGBmD17Nrp37474+Hj069dP8pe4c3NzERYWhmHDhsHNzQ0RERHw9PTUnem5fv06NmzYgGXLluHxxx+Hl5cXkpOTkZubiwMHDgAAMjMz8cMPP2DLli3o06cPRowYgfj4eCQmJqK8vLzhdwwRERHVSb3/1tL9Ki8vx+HDhxETE6Nrs7Kygp+fH/Ly8gyuk5eXh+joaElbQEAA0tPTde8HDRqEXbt24eWXX4aLiwtycnLw448/Yvny5QCAw4cPo6KiAn5+frp13N3d8dBDDyEvLw8DBw5EXl4eevXqBWdnZ8l2pk6dihMnTqBv374G51dWVoaysjLd+5KSEgBARUUFKioq6rhnalY9jqnGawwsrSZLqwdgTXLBmuTB0mpqqHrqOp7ZgsyVK1dQWVkpCQsA4OzsjFOnThlcR6vVGuyv1Wp171etWoWIiAi0b98eNjY2sLKywvr16zF06FDdGHZ2dmjevLnRcYxtp3qZMQkJCYiLi9Nrz8zMhFqtNrpefWRlZZl0vMbA0mqytHoA1iQXrEkeLK0mU9dTWlpap35mCzINZdWqVThw4AB27doFV1dX7N+/H5GRkXBxcZGchWkIMTExkjNGJSUl6NChA/z9/eHo6GiSbVRUVCArKwvDhw+Hra2tScY0N0urydLqAViTXLAmebC0mhqqnuqrGrUxW5BxcnKCtbW13tNCRUVF0Gg0BtfRaDQ19r99+zbmzJmDHTt2ICgoCADQu3dv5OfnY8mSJfDz84NGo0F5eTmuXbsmOSvz13E0Go3e01PV2zU2NwBQKpVQKpV67ba2tib/sjbEmOZmaTVZWj0Aa5IL1iQPllaTqeup61hmu9nXzs4OXl5eyM7O1rVVVVUhOzsbPj4+Btfx8fGR9Afunsqq7l99L4qVlbQsa2trVFVVAQC8vLxga2srGef06dO4ePGibhwfHx8cP35c8vRUVlYWHB0d4eHhcR9VExERkSmZ9dJSdHQ0wsLC0L9/fwwYMAArVqzArVu3EB4eDgAYP3482rVrh4SEBADA9OnT4evri6VLlyIoKAgpKSk4dOgQ1q1bBwBwdHSEr68vZs+eDXt7e7i6uuLLL7/E5s2bsWzZMgB3/x7UxIkTER0djZYtW8LR0RGvvvoqfHx8MHDgQACAv78/PDw88NJLL2HRokXQarWYO3cuIiMjDZ5xISIiIvMwa5AJDQ3F5cuXMW/ePGi1WvTp0wcZGRm6G2svXrwoObsyaNAgbN26FXPnzsWcOXPQtWtXpKeno2fPnro+KSkpiImJwbhx43D16lW4urpi4cKFmDJliq7P8uXLYWVlhdGjR6OsrAwBAQF47733dMutra3x6aefYurUqfDx8UGTJk0QFhaGBQsWPIC9QkRERHVl9pt9o6KiEBUVZXBZTk6OXltISAhCQkKMjqfRaGr945YqlQqJiYlITEw02sfV1VXvV4OJiIiocTH7nyggIiIiqi8GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIiki0GGSIiIpItBhkiIiKSLQYZIiIikq1GEWQSExPh5uYGlUoFb29vHDx4sMb+aWlpcHd3h0qlQq9evbB3717JcoVCYfC1ePFiAEBOTo7RPt999x0A4Pz58waXHzhwoGF2AhEREd0zsweZ1NRUREdHIzY2FkeOHIGnpycCAgJQXFxssH9ubi7Gjh2LiRMn4ujRowgODkZwcDAKCgp0fQoLCyWvpKQkKBQKjB49GgAwaNAgvT6TJk1Cx44d0b9/f8n29u3bJ+nn5eXVcDuDiIiI7onZg8yyZcswefJkhIeHw8PDA2vXroVarUZSUpLB/itXrkRgYCBmz56N7t27Iz4+Hv369cPq1at1fTQajeS1c+dOPPbYY+jUqRMAwM7OTrK8VatW2LlzJ8LDw6FQKCTba9WqlaSvra1tw+0MIiIiuic25tx4eXk5Dh8+jJiYGF2blZUV/Pz8kJeXZ3CdvLw8REdHS9oCAgKQnp5usH9RURH27NmDTZs2GZ3Hrl278PvvvyM8PFxv2ciRI3Hnzh08/PDDeO211zBy5Eij45SVlaGsrEz3vqSkBABQUVGBiooKo+vdi+pxTDVeY2BpNVlaPQBrkgvWJA+WVlND1VPX8cwaZK5cuYLKyko4OztL2p2dnXHq1CmD62i1WoP9tVqtwf6bNm2Cg4MDRo0aZXQeGzZsQEBAANq3b69ra9q0KZYuXYrBgwfDysoKn3zyCYKDg5Genm40zCQkJCAuLk6vPTMzE2q12uj26yMrK8uk4zUGllaTpdUDsCa5YE3yYGk1mbqe0tLSOvUza5B5EJKSkjBu3DioVCqDy3/99Vd8/vnn2LZtm6TdyclJcubnkUcewaVLl7B48WKjQSYmJkayTklJCTp06AB/f384OjqaoJq7CTUrKwvDhw+3mMtcllaTpdUDsCa5YE3yYGk1NVQ91Vc1amPWIOPk5ARra2sUFRVJ2ouKiqDRaAyuo9Fo6tz/q6++wunTp5Gammp0DsnJyWjVqlWNl4yqeXt715g4lUollEqlXrutra3Jv6wNMaa5WVpNllYPwJrkgjXJg6XVZOp66jqWWW/2tbOzg5eXF7Kzs3VtVVVVyM7Oho+Pj8F1fHx8JP2Bu6ezDPXfsGEDvLy84OnpaXAsIQSSk5Mxfvz4Ou2w/Px8tG3bttZ+RERE9GCY/dJSdHQ0wsLC0L9/fwwYMAArVqzArVu3dDfejh8/Hu3atUNCQgIAYPr06fD19cXSpUsRFBSElJQUHDp0COvWrZOMW1JSgrS0NCxdutTotv/zn//g3LlzmDRpkt6yTZs2wc7ODn379gUAbN++HUlJSfjggw9MVToRERHdJ7MHmdDQUFy+fBnz5s2DVqtFnz59kJGRobuh9+LFi7Cy+u+Jo0GDBmHr1q2YO3cu5syZg65duyI9PR09e/aUjJuSkgIhBMaOHWt02xs2bMCgQYPg7u5ucHl8fDwuXLgAGxsbuLu7IzU1Fc8995wJqiYiIiJTMHuQAYCoqChERUUZXJaTk6PXFhISgpCQkBrHjIiIQERERI19tm7danRZWFgYwsLCalyfiIiIzMvsP4hHREREVF8MMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbDDJEREQkWwwyREREJFsMMkRERCRbjSLIJCYmws3NDSqVCt7e3jh48GCN/dPS0uDu7g6VSoVevXph7969kuUKhcLga/Hixbo+bm5uesvffvttyTjff/89hgwZApVKhQ4dOmDRokWmK5qIiIjum9mDTGpqKqKjoxEbG4sjR47A09MTAQEBKC4uNtg/NzcXY8eOxcSJE3H06FEEBwcjODgYBQUFuj6FhYWSV1JSEhQKBUaPHi0Za8GCBZJ+r776qm5ZSUkJ/P394erqisOHD2Px4sWYP38+1q1b1zA7goiIiO6Z2YPMsmXLMHnyZISHh8PDwwNr166FWq1GUlKSwf4rV65EYGAgZs+eje7duyM+Ph79+vXD6tWrdX00Go3ktXPnTjz22GPo1KmTZCwHBwdJvyZNmuiWffjhhygvL0dSUhJ69OiB559/HtOmTcOyZcsaZkcQERHRPbMx58bLy8tx+PBhxMTE6NqsrKzg5+eHvLw8g+vk5eUhOjpa0hYQEID09HSD/YuKirBnzx5s2rRJb9nbb7+N+Ph4PPTQQ3jhhRcwc+ZM2NjY6LYzdOhQ2NnZSbbzzjvv4I8//kCLFi30xisrK0NZWZnufUlJCQCgoqICFRUVRvbCvakex1TjNQaWVpOl1QOwJrlgTfJgaTU1VD11Hc+sQebKlSuorKyEs7OzpN3Z2RmnTp0yuI5WqzXYX6vVGuy/adMmODg4YNSoUZL2adOmoV+/fmjZsiVyc3MRExODwsJC3RkXrVaLjh076m2nepmhIJOQkIC4uDi99szMTKjVaoPzq6+srCyTjtcYWFpNllYPwJrkgjXJg6XVZOp6SktL69TPrEHmQUhKSsK4ceOgUqkk7X89q9O7d2/Y2dnhH//4BxISEqBUKuu1rZiYGMm4JSUl6NChA/z9/eHo6Fi/Av6moqICWVlZGD58OGxtbU0yprlZWk2WVg/AmuSCNcmDpdXUUPVUX9WojVmDjJOTE6ytrVFUVCRpLyoqgkajMbiORqOpc/+vvvoKp0+fRmpqaq1z8fb2xp9//onz58+jW7duRrdTPQdDlEqlwRBka2tr8i9rQ4xpbpZWk6XVA7AmuWBN8mBpNZm6nrqOZdabfe3s7ODl5YXs7GxdW1VVFbKzs+Hj42NwHR8fH0l/4O7pLEP9N2zYAC8vL3h6etY6l/z8fFhZWaFNmza67ezfv19yjS4rKwvdunUzeFmJiIiIHjyzP7UUHR2N9evXY9OmTTh58iSmTp2KW7duITw8HAAwfvx4yc3A06dPR0ZGBpYuXYpTp05h/vz5OHToEKKioiTjlpSUIC0tDZMmTdLbZl5eHlasWIFjx47h559/xocffoiZM2fixRdf1IWUF154AXZ2dpg4cSJOnDiB1NRUrFy5Uu9GYyIiIjIfs98jExoaisuXL2PevHnQarXo06cPMjIydDfWXrx4EVZW/81bgwYNwtatWzF37lzMmTMHXbt2RXp6Onr27CkZNyUlBUIIjB07Vm+bSqUSKSkpmD9/PsrKytCxY0fMnDlTElKaNWuGzMxMREZGwsvLC05OTpg3bx4iIiIaaE8QERHRvTJ7kAGAqKgovTMq1XJycvTaQkJCEBISUuOYERERRkNHv379cODAgVrn1bt3b3z11Ve19iMiIiLzMPulJSIiIqL6YpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIionqprBL49txVHL6iwLfnrqKySjzwOdg88C0SERGR7GUUFCJu9w8ovH4HgDU2nzmEts1UiH3aA4E92z6weTSKMzKJiYlwc3ODSqWCt7c3Dh48WGP/tLQ0uLu7Q6VSoVevXti7d69kuUKhMPhavHgxAOD8+fOYOHEiOnbsCHt7e3Tu3BmxsbEoLy/XjXH+/HmDYxw4cMD0O4CIiEhGMgoKMXXLkf8LMf+lvX4HU7ccQUZB4QObi9mDTGpqKqKjoxEbG4sjR47A09MTAQEBKC4uNtg/NzcXY8eOxcSJE3H06FEEBwcjODgYBQUFuj6FhYWSV1JSEhQKBUaPHg0AOHXqFKqqqvD+++/jxIkTWL58OdauXYs5c+bobW/fvn2Ssby8vBpmRxAREclAZZVA3O4fYOgiUnVb3O4fHthlJrMHmWXLlmHy5MkIDw+Hh4cH1q5dC7VajaSkJIP9V65cicDAQMyePRvdu3dHfHw8+vXrh9WrV+v6aDQayWvnzp147LHH0KlTJwBAYGAgkpOT4e/vj06dOmHkyJGYNWsWtm/frre9Vq1aScaytbVtmB1BREQkAwfPXdU7E/NXAkDh9Ts4eO7qA5mPWe+RKS8vx+HDhxETE6Nrs7Kygp+fH/Ly8gyuk5eXh+joaElbQEAA0tPTDfYvKirCnj17sGnTphrncv36dbRs2VKvfeTIkbhz5w4efvhhvPbaaxg5cqTRMcrKylBWVqZ7X1JSAgCoqKhARUVFjduvq+pxTDVeY2BpNVlaPQBrkgvWJA9yr6nw2q0696uocKz3duq6f8waZK5cuYLKyko4OztL2p2dnXHq1CmD62i1WoP9tVqtwf6bNm2Cg4MDRo0aZXQeZ8+exapVq7BkyRJdW9OmTbF06VIMHjwYVlZW+OSTTxAcHIz09HSjYSYhIQFxcXF67ZmZmVCr1Ua3Xx9ZWVkmHa8xsLSaLK0egDXJBWuSB7nW9PN1BQDr2vudyMfeX4/WezulpaV16mfxTy0lJSVh3LhxUKlUBpf/9ttvCAwMREhICCZPnqxrd3Jykpz5eeSRR3Dp0iUsXrzYaJCJiYmRrFNSUoIOHTrA398fjo71T6V/VVFRgaysLAwfPtxiLnNZWk2WVg/AmuSCNcmD3GuqrBL4eOl+FJWUGbxPRgFA00yJqNChsLZS1Hs71Vc1amPWIOPk5ARra2sUFRVJ2ouKiqDRaAyuo9Fo6tz/q6++wunTp5GammpwrEuXLuGxxx7DoEGDsG7dulrn6+3tXWOCViqVUCqVeu22trYm/7I2xJjmZmk1WVo9AGuSC9YkD3KtyRbA/JE9MHXLESgASZipji2xT/eASml3f9up474x682+dnZ28PLyQnZ2tq6tqqoK2dnZ8PHxMbiOj4+PpD9w9/Scof4bNmyAl5cXPD099Zb99ttvGDZsGLy8vJCcnAwrq9p3RX5+Ptq2fXDPxhMRETVGgT3bYs2L/aBpJr3aoWmmwpoX+z3Q35Ex+6Wl6OhohIWFoX///hgwYABWrFiBW7duITw8HAAwfvx4tGvXDgkJCQCA6dOnw9fXF0uXLkVQUBBSUlJw6NAhvTMqJSUlSEtLw9KlS/W2WR1iXF1dsWTJEly+fFm3rPrMzqZNm2BnZ4e+ffsCALZv346kpCR88MEHDbIfiIiI5CSwZ1sM99Ag72wxMr/6Fv5DvOHTpc19XU6qD7MHmdDQUFy+fBnz5s2DVqtFnz59kJGRobuh9+LFi5KzJYMGDcLWrVsxd+5czJkzB127dkV6ejp69uwpGTclJQVCCIwdO1Zvm1lZWTh79izOnj2L9u3bS5YJ8d+TZPHx8bhw4QJsbGzg7u6O1NRUPPfcc6Ysn4iISLasrRTw7tgSv58U8O7Y8oGHGKARBBkAiIqKQlRUlMFlOTk5em0hISEICQmpccyIiAhEREQYXDZhwgRMmDChxvXDwsIQFhZWYx8iIiIyL7P/IB4RERFRfTHIEBERkWwxyBAREZFsMcgQERGRbDHIEBERkWw1iqeWLFX1o9x1/ZnluqioqEBpaSlKSkpk+YuQhlhaTZZWD8Ca5II1yYOl1dRQ9VT/2/nXn0UxhEGmAd24cQMA0KFDBzPPhIiISJ5u3LiBZs2aGV2uELVFHaq3qqoqXLp0CQ4ODlAoTPMjQdV/iPKXX34x2R+iNDdLq8nS6gFYk1ywJnmwtJoaqh4hBG7cuAEXF5ca/4wQz8g0ICsrK71fDjYVR0dHizgA/srSarK0egDWJBesSR4sraaGqKemMzHVeLMvERERyRaDDBEREckWg4zMKJVKxMbGQqlUmnsqJmNpNVlaPQBrkgvWJA+WVpO56+HNvkRERCRbPCNDREREssUgQ0RERLLFIENERESyxSBDREREssUg00i8/fbbUCgUmDFjRo390tLS4O7uDpVKhV69emHv3r2S5UIIzJs3D23btoW9vT38/Pxw5syZBpy5cXWpaf369RgyZAhatGiBFi1awM/PDwcPHpT0mTBhAhQKheQVGBjYwLM3rC41bdy4UW++KpVK0kdun9OwYcP0alIoFAgKCtL1MefnNH/+fL1tu7u717hOYz+W7rWmxn4s3Ws9cjiO7rWmxn4cVfvtt9/w4osvolWrVrC3t0evXr1w6NChGtfJyclBv379oFQq0aVLF2zcuFGvT2JiItzc3KBSqeDt7a33/awvBplG4LvvvsP777+P3r1719gvNzcXY8eOxcSJE3H06FEEBwcjODgYBQUFuj6LFi3Cu+++i7Vr1+Lbb79FkyZNEBAQgDt37jR0GRJ1rSknJwdjx47FF198gby8PHTo0AH+/v747bffJP0CAwNRWFioe3300UcNOX2D6loTcPcXLv863wsXLkiWy+1z2r59u6SegoICWFtbIyQkRNLPnJ9Tjx49JNv++uuvjfaVy7F0LzXJ4Vi6l3oAeRxH91KTHI6jP/74A4MHD4atrS0+++wz/PDDD1i6dClatGhhdJ1z584hKCgIjz32GPLz8zFjxgxMmjQJn3/+ua5PamoqoqOjERsbiyNHjsDT0xMBAQEoLi6+/0kLMqsbN26Irl27iqysLOHr6yumT59utO+YMWNEUFCQpM3b21v84x//EEIIUVVVJTQajVi8eLFu+bVr14RSqRQfffRRg8zfkHup6e/+/PNP4eDgIDZt2qRrCwsLE88884zpJ3oP7qWm5ORk0axZM6PLLeFzWr58uXBwcBA3b97UtZnzc4qNjRWenp517i+HY+lea/q7xnYs3Ws9cjiO7vczamzHkRBCvP766+LRRx+9p3Vee+010aNHD0lbaGioCAgI0L0fMGCAiIyM1L2vrKwULi4uIiEh4f4mLITgGRkzi4yMRFBQEPz8/Grtm5eXp9cvICAAeXl5AO6mYq1WK+nTrFkzeHt76/o8CPdS09+VlpaioqICLVu2lLTn5OSgTZs26NatG6ZOnYrff//dVNOtk3ut6ebNm3B1dUWHDh3wzDPP4MSJE7pllvA5bdiwAc8//zyaNGkiaTfn53TmzBm4uLigU6dOGDduHC5evGi0r1yOpXup6e8a47F0r/XI4Ti6n8+oMR5Hu3btQv/+/RESEoI2bdqgb9++WL9+fY3r1HY8lZeX4/Dhw5I+VlZW8PPzM8lnxT8aaUYpKSk4cuQIvvvuuzr112q1cHZ2lrQ5OztDq9Xqlle3GevT0O61pr97/fXX4eLiIvnCBwYGYtSoUejYsSN++uknzJkzByNGjEBeXh6sra1NNXWj7rWmbt26ISkpCb1798b169exZMkSDBo0CCdOnED79u1l/zkdPHgQBQUF2LBhg6TdnJ+Tt7c3Nm7ciG7duqGwsBBxcXEYMmQICgoK4ODgoNdfDsfSvdb0d43tWLrXeuRwHN3PZ9QYjyMA+Pnnn7FmzRpER0djzpw5+O677zBt2jTY2dkhLCzM4DrGjqeSkhLcvn0bf/zxByorKw32OXXq1P1P+r7P6VC9XLx4UbRp00YcO3ZM11bb6X1bW1uxdetWSVtiYqJo06aNEEKIb775RgAQly5dkvQJCQkRY8aMMd3kjahPTX+VkJAgWrRoIVnfkJ9++kkAEPv27buf6dbJ/dYkhBDl5eWic+fOYu7cuUII+X9OERERolevXrX2e5Cf09/98ccfwtHRUXzwwQcGlzf2Y8mQ2mr6q8Z4LP3dvdQjROM7jgy5l5oa63Fka2srfHx8JG2vvvqqGDhwoNF1unbtKt566y1J2549ewQAUVpaKn777TcBQOTm5kr6zJ49WwwYMOC+58xLS2Zy+PBhFBcXo1+/frCxsYGNjQ2+/PJLvPvuu7CxsUFlZaXeOhqNBkVFRZK2oqIiaDQa3fLqNmN9GlJ9aqq2ZMkSvP3228jMzKz1xtNOnTrByckJZ8+eNXUJeu6npmq2trbo27evbr5y/pxu3bqFlJQUTJw4sdbtPMjP6e+aN2+Ohx9+2Oi2G/uxZEhtNVVrrMfS39W1nmqN7TgypK41NebjqG3btvDw8JC0de/evcZLZsaOJ0dHR9jb28PJyQnW1tYN9lkxyJjJE088gePHjyM/P1/36t+/P8aNG4f8/HyDpxB9fHyQnZ0tacvKyoKPjw8AoGPHjtBoNJI+JSUl+Pbbb3V9GlJ9agLuPnkQHx+PjIwM9O/fv9bt/Prrr/j999/Rtm1bU5egp741/VVlZSWOHz+um69cPyfg7iPLZWVlePHFF2vdzoP8nP7u5s2b+Omnn4xuu7EfS4bUVhPQuI+lv6tLPX/V2I4jQ+paU2M+jgYPHozTp09L2n788Ue4uroaXae248nOzg5eXl6SPlVVVcjOzjbNZ3Xf53TIZP5+ev+ll14Sb7zxhu79N998I2xsbMSSJUvEyZMnRWxsrLC1tRXHjx/X9Xn77bdF8+bNxc6dO8X3338vnnnmGdGxY0dx+/btB1mKTm01vf3228LOzk58/PHHorCwUPe6ceOGEOLukzWzZs0SeXl54ty5c2Lfvn2iX79+omvXruLOnTsPuhwhRO01xcXFic8//1z89NNP4vDhw+L5558XKpVKnDhxQtdHbp9TtUcffVSEhobqtZv7c/rnP/8pcnJyxLlz58Q333wj/Pz8hJOTkyguLjZYjxyOpXutqbEfS/dajxyOo3utqVpjPY6EEOLgwYPCxsZGLFy4UJw5c0Z8+OGHQq1Wiy1btuj6vPHGG+Kll17Svf/555+FWq0Ws2fPFidPnhSJiYnC2tpaZGRk6PqkpKQIpVIpNm7cKH744QcREREhmjdvLrRa7X3PmUGmEfn7Pya+vr4iLCxM0mfbtm3i4YcfFnZ2dqJHjx5iz549kuVVVVXizTffFM7OzkKpVIonnnhCnD59+gHM3rDaanJ1dRUA9F6xsbFCCCFKS0uFv7+/aN26tbC1tRWurq5i8uTJJvny11dtNc2YMUM89NBDws7OTjg7O4snn3xSHDlyRDKG3D4nIYQ4deqUACAyMzP11jf35xQaGiratm0r7OzsRLt27URoaKg4e/asbrkcj6V7ramxH0v3Wo8cjqP6fO8a83FUbffu3aJnz55CqVQKd3d3sW7dOsnysLAw4evrK2n74osvRJ8+fYSdnZ3o1KmTSE5O1ht31apVus90wIAB4sCBAyaZr0IIIe7/vA4RERHRg8d7ZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIiISLYYZIiIiEi2GGSIiIhIthhkiIjugUKhQHp6urmnQUT/h0GGiGRjwoQJUCgUeq/AwEBzT42IzMTG3BMgIroXgYGBSE5OlrQplUozzYaIzI1nZIhIVpRKJTQajeTVokULAHcv+6xZswYjRoyAvb09OnXqhI8//liy/vHjx/H444/D3t4erVq1QkREBG7evCnpk5SUhB49ekCpVKJt27aIioqSLL9y5QqeffZZqNVqdO3aFbt27WrYoonIKAYZIrIob775JkaPHo1jx45h3LhxeP7553Hy5EkAwK1btxAQEIAWLVrgu+++Q1paGvbt2ycJKmvWrEFkZCQiIiJw/Phx7Nq1C126dJFsIy4uDmPGjMH333+PJ598EuPGjcPVq1cfaJ1E9H9M8je0iYgegLCwMGFtbS2aNGkieS1cuFAIIQQAMWXKFMk63t7eYurUqUIIIdatWydatGghbt68qVu+Z88eYWVlJbRarRBCCBcXF/Gvf/3L6BwAiLlz5+re37x5UwAQn332mcnqJKK64z0yRCQrjz32GNasWSNpa9mype5/+/j4SJb5+PggPz8fAHDy5El4enqiSZMmuuWDBw9GVVUVTp8+DYVCgUuXLuGJJ56ocQ69e/fW/e8mTZrA0dERxcXF9S2JiO4DgwwRyUqTJk30LvWYir29fZ362draSt4rFApUVVU1xJSIqBa8R4aILMqBAwf03nfv3h0A0L17dxw7dgy3bt3SLf/mm29gZWWFbt26wcHBAW5ubsjOzn6gcyai+uMZGSKSlbKyMmi1WkmbjY0NnJycAABpaWno378/Hn30UXz44Yc4ePAgNmzYAAAYN24cYmNjERYWhvnz5+Py5ct49dVX8dJLL8HZ2RkAMH/+fEyZMgVt2rTBiBEjcOPGDXzzzTd49dVXH2yhRFQnDDJEJCsZGRlo27atpK1bt244deoUgLtPFKWkpOCVV15B27Zt8dFHH8HDwwMAoFar8fnnn2P69Ol45JFHoFarMXr0aCxbtkw3VlhYGO7cuYPly5dj1qxZcHJywnPPPffgCiSie6IQQghzT4KIyBQUCgV27NiB4OBgc0+FiB4Q3iNDREREssUgQ0RERLLFe2SIyGLwSjnR/x6ekSEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2WKQISIiItlikCEiIiLZYpAhIiIi2fr/hryokW6BVfUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(range(1, len(losses)+1), losses, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, json, torch\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "SYSTEM_TEXT = (\n",
        "     \"\"\"You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
        "    1.  **Plan Generation:**\n",
        "      If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
        "      You MUST respond with the complete `{\"task_plan\": [{\"step_id\": , \"description\":}...]}` JSON for the entire task.\n",
        "      If the user requests a specific course, include the specific course name in the plan description.\n",
        "\n",
        "    2.  **Action Generation:**\n",
        "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
        "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.\n",
        "      For input actions, ensure the `value` field matches the specific data from the plan.\"\"\"\n",
        ")\n",
        "\n",
        "def build_inputs(user_prompt: str):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_TEXT},\n",
        "        {\"role\": \"user\",   \"content\": user_prompt},\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    return {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "# 1) 균형 검사 유틸\n",
        "def is_balanced_json_fragment(s: str) -> bool:\n",
        "    in_str = False\n",
        "    esc = False\n",
        "    stack = []\n",
        "    for ch in s:\n",
        "        if in_str:\n",
        "            if esc:\n",
        "                esc = False\n",
        "            elif ch == '\\\\':\n",
        "                esc = True\n",
        "            elif ch == '\"':\n",
        "                in_str = False\n",
        "            continue\n",
        "        else:\n",
        "            if ch == '\"':\n",
        "                in_str = True\n",
        "            elif ch == '{':\n",
        "                stack.append('}')\n",
        "            elif ch == '[':\n",
        "                stack.append(']')\n",
        "            elif ch in ('}', ']'):\n",
        "                if not stack or stack[-1] != ch:\n",
        "                    return False\n",
        "                stack.pop()\n",
        "    return len(stack) == 0 and len(s) > 0\n",
        "\n",
        "# 2) 가장 긴 균형 잡힌 JSON 덩어리 추출\n",
        "def longest_balanced_json(text: str) -> str | None:\n",
        "    # 첫 { 또는 [ 부터 스캔\n",
        "    start = None\n",
        "    for i, ch in enumerate(text):\n",
        "        if ch in '{[':\n",
        "            start = i\n",
        "            break\n",
        "    if start is None:\n",
        "        return None\n",
        "\n",
        "    in_str = False\n",
        "    esc = False\n",
        "    stack = []\n",
        "    last_good = None\n",
        "    for i, ch in enumerate(text[start:], start=start):\n",
        "        if in_str:\n",
        "            if esc:\n",
        "                esc = False\n",
        "            elif ch == '\\\\':\n",
        "                esc = True\n",
        "            elif ch == '\"':\n",
        "                in_str = False\n",
        "        else:\n",
        "            if ch == '\"':\n",
        "                in_str = True\n",
        "            elif ch == '{':\n",
        "                stack.append('}')\n",
        "            elif ch == '[':\n",
        "                stack.append(']')\n",
        "            elif ch in ('}', ']'):\n",
        "                if not stack or stack[-1] != ch:\n",
        "                    break\n",
        "                stack.pop()\n",
        "                if not stack:\n",
        "                    last_good = i + 1\n",
        "    return text[start:last_good].strip() if last_good else None\n",
        "\n",
        "# 3) 스톱 조건 교체: 단일 '}' 대신 '균형 JSON이면 멈춤'\n",
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "import re, torch\n",
        "\n",
        "class StopOnBalancedJSON(StoppingCriteria):\n",
        "    def __init__(self, tokenizer, lookback_tokens=400):\n",
        "        self.tok = tokenizer\n",
        "        self.lookback_tokens = lookback_tokens\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        txt = self.tok.decode(input_ids[0][-self.lookback_tokens:], skip_special_tokens=True)\n",
        "        # 마지막 JSON 시작 후보를 대략 잡아 균형 확인\n",
        "        m = re.search(r'([\\{\\[].*)$', txt, flags=re.DOTALL)\n",
        "        cand = m.group(1) if m else txt\n",
        "        return is_balanced_json_fragment(cand)\n",
        "\n",
        "stoppers = StoppingCriteriaList([StopOnBalancedJSON(tokenizer)])\n",
        "# 4) generate_json 후처리 교체: 정규식 candidates 대신 longest_balanced_json 사용\n",
        "def generate_json(user_prompt: str, max_new_tokens=256, do_sample=False):\n",
        "    inputs = build_inputs(user_prompt)\n",
        "    input_len = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=do_sample,\n",
        "            temperature=0.7 if do_sample else None,\n",
        "            top_p=0.9 if do_sample else None,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            stopping_criteria=stoppers,\n",
        "        )\n",
        "\n",
        "    # 입력 길이 이후(신규 생성분)만 디코딩\n",
        "    new_tokens = out_ids[0, input_len:]\n",
        "    text = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    # 균형 잡힌 JSON만 잘라서 파싱\n",
        "    jb = longest_balanced_json(text)\n",
        "    if jb is None:\n",
        "        return text  # 디버그용으로 원문 반환\n",
        "    try:\n",
        "        return json.loads(jb)\n",
        "    except Exception:\n",
        "        return jb  # 파싱 실패 시 문자열로 반환(디버그)\n"
      ],
      "metadata": {
        "id": "CBCZBaPBLRms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 테스트 ----\n",
        "plan_prompt = \"{'user_request': '자퇴신청'}\"\n",
        "plan_result = generate_json(plan_prompt)\n",
        "print(plan_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jISvRcOXfYY",
        "outputId": "62bf850b-2377-4821-efd5-e8b44b115b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'task_plan': [{'step_id': 1, 'task_plan': \"좌측 메뉴에서 '【학생신청】신청함'를 클릭한다.\"}, {'step_id': '2', 'task_plan': \"화면에서 '[학적]자퇴신청' 항목을 찾아 해당 그리드의 행번호를 확인한다.\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------모델 쓰는 방법 가이드----------\n",
        "\n",
        "# 1. 사용자 입력을 넣고, plan을 생성\n",
        "import json\n",
        "\n",
        "user_req = input(\"무엇을 하고 싶나요? (예: 휴학신청): \").strip()\n",
        "\n",
        "plan_payload = {\"user_request\": user_req}\n",
        "plan_prompt = json.dumps(plan_payload, ensure_ascii=False)\n",
        "\n",
        "plan_result = generate_json(plan_prompt, do_sample=False)\n",
        "print(\"[PLAN RESULT]\")\n",
        "print(plan_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9zLvYrpdzCO",
        "outputId": "5191d3c8-bab8-498d-adc2-c6f4cc533919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "무엇을 하고 싶나요? (예: 휴학신청): 자퇴신청\n",
            "[PLAN RESULT]\n",
            "{'task_plan': [{'step_id': 1, 'task_plan': \"좌측 메뉴에서 '【학생신청】신청함'를 클릭한다.\"}, {'step_id': '2', 'task_plan': \"화면에서 '[학적]자퇴신청' 항목을 찾아 해당 그리드의 행번호를 확인한다.\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, ast\n",
        "\n",
        "def extract_steps(plan_result):\n",
        "    # 1) dict면 바로 사용\n",
        "    if isinstance(plan_result, dict):\n",
        "        steps = plan_result.get(\"task_plan\") or plan_result.get(\"task_plans\") or []\n",
        "        return [(int(s.get(\"step_id\", i+1)), str(s.get(\"task_plan\",\"\"))) for i, s in enumerate(steps)]\n",
        "\n",
        "    # 2) 문자열이면 JSON → 실패 시 literal_eval 순서로 파싱\n",
        "    s = str(plan_result).strip()\n",
        "    try:\n",
        "        obj = json.loads(s)\n",
        "    except Exception:\n",
        "        obj = ast.literal_eval(s)  # '...' 스타일 파싱\n",
        "\n",
        "    steps = obj.get(\"task_plan\") or obj.get(\"task_plans\") or []\n",
        "    return [(int(s.get(\"step_id\", i+1)), str(s.get(\"task_plan\",\"\"))) for i, s in enumerate(steps)]\n",
        "\n",
        "print(extract_steps(plan_result))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgWLz0PsVV9h",
        "outputId": "1b37fc3e-6cfe-473f-90f5-bce17106fe0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, \"좌측 메뉴에서 '【학생신청】신청함'를 클릭한다.\"), (2, \"화면에서 '[학적]자퇴신청' 항목을 찾아 해당 그리드의 행번호를 확인한다.\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# 1) 정규식으로 뽑은 결과 예시 (이미 너가 만든 result)\n",
        "# result = [(1, \"좌측 메뉴에서 '【학생신청】신청함'를 클릭한다.\"), (2, \"...\"), (3, \"...\")]\n",
        "\n",
        "# 여기에 state 넣으면 됨\n",
        "obs_map = {\n",
        "    1: {\n",
        "        \"sidebar\": [{\"id\": \"18555\", \"label\": \"【학생신청】신청함\", \"expanded\": False, \"checked\": False}]\n",
        "    },\n",
        "    2: {\n",
        "        \"sidebar\": [{\"id\": \"18555\", \"label\": \"【학생신청】신청함\", \"expanded\": False, \"checked\": True}]\n",
        "    },\n",
        "    3: {\n",
        "        \"sidebar\": [{\"id\": \"fc\", \"label\": \"수업/강의평가\", \"expanded\": True, \"checked\": True, \"sub_items\": [{\"id\": \"fm\", \"label\": \"종합강의시간표조회\", \"checked\": True}]}]\n",
        "    }\n",
        "}\n",
        "\n",
        "def build_action_prompt(user_request: str, step_id: int, task_plan: str, observations: dict | None):\n",
        "    payload = {\n",
        "        \"user_request\": user_request,\n",
        "        \"task_plan\": task_plan,\n",
        "        \"step_id\": str(step_id),\n",
        "    }\n",
        "    if observations is not None:\n",
        "        payload[\"observations\"] = observations\n",
        "    # 문자열 깨짐 방지: 반드시 json.dumps 사용\n",
        "    return json.dumps(payload, ensure_ascii=False)\n",
        "\n",
        "def run_actions_from_regex_result(result_list, user_request=\"휴학신청\", obs_map=None, max_new_tokens=256):\n",
        "    outputs = []\n",
        "    for sid, tplan in result_list:\n",
        "        obs = (obs_map or {}).get(sid)\n",
        "        action_prompt = build_action_prompt(user_request, sid, tplan, obs)\n",
        "        out = generate_json(action_prompt, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "        outputs.append((sid, tplan, out))\n",
        "    return outputs\n",
        "\n",
        "# ---- 실행 ----\n",
        "actions = run_actions_from_regex_result(extract_steps(plan_result), user_request=\"휴학신청\", obs_map=obs_map, max_new_tokens=256)\n",
        "\n",
        "for sid, tplan, action in actions:\n",
        "    print(\"------------------------------------------------\")\n",
        "    print(f\"[STEP {sid}] {tplan}\")\n",
        "    print(\"[ACTION RESULT]\\n\", action)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l4lzkm5W4zt",
        "outputId": "b5565af1-f35e-4617-ecf1-914fdbbd53d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "[STEP 1] 좌측 메뉴에서 '【학생신청】신청함'를 클릭한다.\n",
            "[ACTION RESULT]\n",
            " {'function': 'click', 'control_label': '【학생신청】신청함', 'control_type': 'tree-item', 'value': '', 'args': {'role': 'treeitem', 'aria-label': '【학생신청】신청함'}, 'status': 'CONTINUE'}\n",
            "------------------------------------------------\n",
            "[STEP 2] 화면에서 '[학적]자퇴신청' 항목을 찾아 해당 그리드의 행번호를 확인한다.\n",
            "[ACTION RESULT]\n",
            " {'function': 'find', 'control_label': '[학적]자퇴신청', 'control_type': 'gridcell', 'value': '', 'args': {'role': 'gridcell', 'aria-label': '[학적]자퇴신청'}, 'status': 'FINISH'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()  # ▶ 허깅페이스 토큰 입력 (Settings > Access Tokens에서 생성한 토큰)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "326a907679c547ceb91d31ae29093c66",
            "8f9840504fce49728aeee44c5de76ef0",
            "6d6a9e12155c486bb81216418477c7c8",
            "28cc0b7a0a79402287b51c61fe003c94",
            "bce08e409d5449a9bc3f179c71a7bf4d",
            "69b039c24e424c1ebdc448a31aeb6651",
            "eb8e335e2a25474ab51038d1086bd691",
            "04512b6707d84b519b572ab4fc1e946e",
            "980449282b6f46c8bdb101912d695567",
            "83a70e39556544aaa33768c141c65f27",
            "951b67b21f7341ae99e1b653894973a1",
            "d8305bae8a0740a986698182e73dd8d4",
            "c8022be555644084a0388fd2814bae31",
            "787a5ed0b08543af8d78736b1f9ec947",
            "4ee4d62335cf4cc09b347d4978812931",
            "6d574d3627e340ec87cd0efc1d3e117a",
            "cebbc437fa874bf68fb1c28d758e6c78",
            "3d360f26f00e4b0cb120f5e18f6959a5",
            "5fa4c0caa3194a3b9150a34613301ba6",
            "56761b43ca0c495eafd8747260cfadce"
          ]
        },
        "id": "qP10QswjdIzi",
        "outputId": "5a9985a0-30f9-4181-a082-4a5fae860b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "326a907679c547ceb91d31ae29093c66"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from huggingface_hub import HfApi, create_repo, upload_folder\n",
        "\n",
        "BASE_REPO = \"leeChaerin/PlanModel_v1\"      # 학습 때 사용한 베이스\n",
        "ADAPTER_DIR = \"./adapters/epoch_009\"       # 저장된 LoRA 어댑터 폴더\n",
        "HF_REPO_ID = \"leeChaerin/ActionModel_v5\"  # 새로 만들 허깅페이스 repo 이름\n",
        "\n",
        "# (1) 허브에 리포지토리 생성(이미 있으면 skip=True)\n",
        "create_repo(repo_id=HF_REPO_ID, private=False, exist_ok=True)\n",
        "\n",
        "# (2) 어댑터 폴더 업로드\n",
        "upload_folder(\n",
        "    repo_id=HF_REPO_ID,\n",
        "    folder_path=ADAPTER_DIR,\n",
        "    path_in_repo=\".\", # 루트에 업로드\n",
        ")\n",
        "print(f\"[OK] LoRA adapter uploaded -> https://huggingface.co/{HF_REPO_ID}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "a178ede343764e99a0b494040d0dc3b8",
            "0d0572b343ff48589a174e32dacf0aa8",
            "9d5f34d61b9e4da298d1f7532891699e",
            "07d5a06f841f42cdbe0fbf360575eb19",
            "adf078c44c83474384ee18b72ff9ccd3",
            "84c3a8d4455c4a5fba60e9ab51b28677",
            "3e0446f5cd6d4af591574b54d55d0ee1",
            "67fc1f6e6afc439cb6aad08d36ba845f",
            "b8eb42b0a7d247e6978779e1d4747890",
            "3adf2ce192bd402c8eab2344b7155740",
            "42d294d07a364f0da71bb20bf18d2d5b",
            "8da0739ff2654f26b4c8533b49ae9879",
            "41e872ea982f4c3e85c4c2b762d888e1",
            "62a1a383481b4012a905bf524766997f",
            "a70113a48f3741b3b7187ef3daed523e",
            "802c626be90b49d1b3bfd73a60f208a5",
            "df21bb2c439f4df7907a2cc0b7efbb48",
            "2c4675f6e9754073bac6d4b150df46d3",
            "4e26c1b57fce436596abd240bcfab5d1",
            "f98a4a8ee6f145b384538f8518a3afad",
            "8464eaa52e8e48f097da42bb484bc94b",
            "974fe201f925432bb1a0bf7f1661340a",
            "e53b3429fb3740c8aa8288aef548398d",
            "f810fc63cca34b3280a0232edc5ebc06",
            "b2b683c47c5b47b78ab4e920836a35f2",
            "7ec89d8f36c244869d154ea9909d18d2",
            "3bb16a5120b5448188136489598f325c",
            "69943c5a394c426b8650dddc54f2648f",
            "7a955e8436ca4cb1aba052b8f11f8c10",
            "685f04b682c34aafa6d3bac42fcca6c9",
            "a7786cc6fbf14b7f9fe2512e9946be43",
            "9259edeaf3f5474c8c302f5db4ac3c60",
            "51a2aff44c12484fb6a67e305c773ee4",
            "3628ab2a40214626b04b6f63f6b1549f",
            "83aa42a617eb48c99196c0121d02a59a",
            "e370524be2ea43c1ab631ad1a9bcf83d",
            "4c70b7fa1caf4b7b9e5f6283938c6900",
            "ac28a8b464f24135a46ccd944ea19183",
            "345ee026e0a24f33b338891081e97f55",
            "53036b8d4ee2445ea4ac78bc9f29d255",
            "598fd38ecc604290a78b9ca990b1b539",
            "24992079bab84a98a444d5686ffbfd59",
            "e17a97ddfd8f486fa55b2852fee5e47e",
            "3ac934d066da4302a74451f3ac0ffa91"
          ]
        },
        "id": "AL2_bt0odOsg",
        "outputId": "765d848a-9e11-45cc-d7c7-f5a79e2948e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a178ede343764e99a0b494040d0dc3b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8da0739ff2654f26b4c8533b49ae9879"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  .../epoch_009/tokenizer.json: 100%|##########| 17.2MB / 17.2MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e53b3429fb3740c8aa8288aef548398d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...adapter_model.safetensors:   1%|          |  559kB / 92.1MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3628ab2a40214626b04b6f63f6b1549f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] LoRA adapter uploaded -> https://huggingface.co/leeChaerin/ActionModel_v5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_prompt = \"\"\"{\n",
        " 'user_request': '휴학신청',\n",
        " 'task_plan': \"좌측 메뉴에서 '학생신청(기타)'를 펼친다\",\n",
        " 'step_id': '1',\n",
        " 'observations': {'sidebar': [{'id':'d7','label':'학생신청(기타)','expanded': false}]}]}\n",
        "}\"\"\"\n",
        "print(generate_json(action_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCX6O6OgSXQ2",
        "outputId": "fff21b9a-943f-43c5-f5a0-fa32e25da962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'function': 'click', 'control_label': '학생신청(기타)', 'control_type': 'tree-item', 'value': '', 'args': {'role': 'treeitem', 'aria-label': '학생신청(기타)'}, 'status': 'CONTINUE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, json, re\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "BASE_REPO   = \"leeChaerin/PlanModel_v1\"   # 학습 시 썼던 베이스\n",
        "ADAPTER_DIR = \"./adapters/epoch_002\"      # 저장해둔 LoRA 어댑터 폴더로 변경\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_REPO, padding_side=\"left\", trust_remote_code=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_REPO,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
        "model.eval()\n",
        "print(\"[OK] Adapter loaded:\", ADAPTER_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DLasx0x7k4m",
        "outputId": "ded31e40-7405-4ded-a267-44968eabd9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Adapter loaded: ./adapters/epoch_002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install outlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC_iDawZ-fGn",
        "outputId": "dbf2cfc5-7ce4-414a-ce06-4b9587dbdbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: outlines in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from outlines) (3.1.6)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from outlines) (3.1.2)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.12/dist-packages (from outlines) (5.6.3)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from outlines) (2.11.10)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from outlines) (4.25.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from outlines) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from outlines) (4.15.0)\n",
            "Requirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from outlines) (0.2.11)\n",
            "Requirement already satisfied: genson in /usr/local/lib/python3.12/dist-packages (from outlines) (1.3.0)\n",
            "Requirement already satisfied: jsonpath_ng in /usr/local/lib/python3.12/dist-packages (from outlines) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->outlines) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->outlines) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->outlines) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->outlines) (3.0.3)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.12/dist-packages (from jsonpath_ng->outlines) (3.11)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines) (0.28.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 형식 고정화 라이브러리 넣기\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Dict, Any, Literal\n",
        "from outlines.models.transformers import Transformers\n",
        "from outlines import Generator\n",
        "\n",
        "# 'args'에 들어갈 내용 정의\n",
        "class ClickArgs(BaseModel):\n",
        "    role: str\n",
        "    aria_label: str = Field(alias=\"aria-label\")\n",
        "\n",
        "# 최종 출력 JSON 구조 정의\n",
        "class ActionModel(BaseModel):\n",
        "    function: str\n",
        "    control_label: str\n",
        "    control_type: str\n",
        "    args: ClickArgs\n",
        "    status: Literal[\"CONTINUE\", \"FINISH\"]\n",
        "\n",
        "\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "hub_repo_name = \"leeChaerin/PlanModel_v1\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    hub_repo_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "# 토크나이저도 불러와야 합니다.\n",
        "tokenizer = AutoTokenizer.from_pretrained(hub_repo_name)\n",
        "\n",
        "adapter_path = \"./model_epoch_009\"\n",
        "\n",
        "# 'model' 객체가 여기서 새로 생성됩니다.\n",
        "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "\n",
        "# --- (C) 추론 준비 ---\n",
        "model.eval()\n",
        "print(f\"'{adapter_path}'에서 어댑터를 성공적으로 로드했습니다.\")\n",
        "\n",
        "outlines_model = Transformers(model=model, tokenizer=tokenizer)\n",
        "action_generator = Generator(outlines_model, ActionModel)\n",
        "\n",
        "user_input = input(\"요청사항을 입력하세요: \")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\",\n",
        "    \"content\": \"You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state).\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "    {'user_request': '{user_input}',\n",
        "     'observations': {'sidebar': [{'id': 'd7', 'label': '학생신청(기타)', 'expanded': false},{'id': 'e5', 'label': '공지사항', 'expanded': true, 'sub_items': [{'id': 'lq', 'label': '공지사항조회', 'checked': true}]}]}\n",
        "    \"\"\"},\n",
        "]\n",
        "\n",
        "prompt_string = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True  # '[ASSISTANT]' 프롬프트를 자동으로 추가\n",
        ")\n",
        "\n",
        "print(f\"---  Action 생성 ---\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # action_generator가 프롬프트를 받아 Pydantic 객체를 반환합니다.\n",
        "    action_result = action_generator(prompt_string, max_new_tokens=256)\n",
        "\n",
        "\n",
        "# --- 3. 결과 출력 ---\n",
        "# action_result는 Pydantic 객체이므로, .model_dump_json()을 사용해\n",
        "# 깔끔한 JSON 문자열로 변환합니다.\n",
        "\n",
        "print(\"\\n--- Outlines가 강제한 JSON 출력 ---\")\n",
        "try:\n",
        "    print(action_result.model_dump_json(indent=2))\n",
        "except Exception as e:\n",
        "    print(f\"JSON 변환 오류: {e}\")\n",
        "    print(action_result) # Pydantic 객체 원본 출력\n",
        "\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\",\n",
        "    \"content\": \"You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state).\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "    {'user_request': '{user_input}',\n",
        "    'observations': {\"sidebar\": [{\"id\": \"d7\", \"label\": \"학생신청(기타)\", \"expanded\": true, \"sub_items\": [{\"id\": \"ee\", \"label\": \"불교동아리가입\", \"checked\": false}]}]}}}\n",
        "    \"\"\"},\n",
        "]\n",
        "\n",
        "prompt_string = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True  # '[ASSISTANT]' 프롬프트를 자동으로 추가\n",
        ")\n",
        "\n",
        "print(f\"---  Action2 생성 ---\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # action_generator가 프롬프트를 받아 Pydantic 객체를 반환합니다.\n",
        "    action_result = action_generator(prompt_string, max_new_tokens=256)\n",
        "\n",
        "\n",
        "# --- 3. 결과 출력 ---\n",
        "# action_result는 Pydantic 객체이므로, .model_dump_json()을 사용해\n",
        "# 깔끔한 JSON 문자열로 변환합니다.\n",
        "\n",
        "print(\"\\n--- Outlines가 강제한 JSON 출력 ---\")\n",
        "try:\n",
        "    print(action_result.model_dump_json(indent=2))\n",
        "except Exception as e:\n",
        "    print(f\"JSON 변환 오류: {e}\")\n",
        "    print(action_result) # Pydantic 객체 원본 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "U-9Qz4et82yC",
        "outputId": "6516c0e3-b669-4e76-b7c4-127e5fe14468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'./model_epoch_009'에서 어댑터를 성공적으로 로드했습니다.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3472146195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0moutlines_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0maction_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutlines_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActionModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"요청사항을 입력하세요: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/outlines/generator.py\u001b[0m in \u001b[0;36mGenerator\u001b[0;34m(model, output_type, backend, processor)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSteerableGenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mSteerableGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/outlines/generator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, output_type, backend_name)\u001b[0m\n\u001b[1;32m    244\u001b[0m                 )\n\u001b[1;32m    245\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJsonSchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 self.logits_processor = get_json_schema_logits_processor(\n\u001b[0m\u001b[1;32m    247\u001b[0m                     \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/outlines/backends/__init__.py\u001b[0m in \u001b[0;36mget_json_schema_logits_processor\u001b[0;34m(backend_name, model, json_schema)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_json_schema_logits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/outlines/backends/outlines_core.py\u001b[0m in \u001b[0;36mget_json_schema_logits_processor\u001b[0;34m(self, json_schema)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \"\"\"\n\u001b[1;32m    251\u001b[0m         \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutlines_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_regex_from_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_regex_logits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_regex_logits_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/outlines/backends/outlines_core.py\u001b[0m in \u001b[0;36mget_regex_logits_processor\u001b[0;34m(self, regex)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mOutlinesCoreLogitsProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_library_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_once(user_prompt: str, max_new_tokens=256, do_sample=False, temperature=0.7, top_p=0.9):\n",
        "    inputs = build_inputs(user_prompt)\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=do_sample,\n",
        "            temperature=temperature if do_sample else None,\n",
        "            top_p=top_p if do_sample else None,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "    text = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
        "    return text\n",
        "\n",
        "# 모델 출력에서 마지막 assistant 부분만(=정답 JSON) 뽑고 싶으면:\n",
        "ASSISTANT_SPLIT_RE = re.compile(r\"(?:<<assistant>>|assistant\\n|assistant:)\", re.IGNORECASE)\n",
        "\n",
        "def extract_assistant_text(full_text: str):\n",
        "    # 템플릿에 따라 전체 대화가 포함될 수 있어, 뒤쪽 JSON을 heuristics로 추출\n",
        "    # 단순화: 중괄호 블록 중 마지막 JSON 객체/배열 추출\n",
        "    candidates = re.findall(r\"(\\{.*\\}|\\[.*\\])\", full_text, flags=re.DOTALL)\n",
        "    return candidates[-1].strip() if candidates else full_text.strip()\n",
        "\n",
        "def try_parse_json(s: str):\n",
        "    try:\n",
        "        return json.loads(s), None\n",
        "    except Exception as e:\n",
        "        return None, e\n"
      ],
      "metadata": {
        "id": "BIvroOVULb6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (A) Plan Generation 테스트\n",
        "plan_prompt = \"{'user_request': '휴학신청'}\"\n",
        "gen_plan = generate_once(plan_prompt, do_sample=False)\n",
        "print(\"\\n[RAW OUTPUT - PLAN]\\n\", gen_plan)\n",
        "\n",
        "only_json = extract_assistant_text(gen_plan)\n",
        "parsed, err = try_parse_json(only_json)\n",
        "print(\"\\n[PARSED JSON - PLAN]\\n\", parsed if err is None else only_json)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQpo5o5FLc7l",
        "outputId": "a1f2e5f3-10c0-4d69-d1e5-1c5b7ac00738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[RAW OUTPUT - PLAN]\n",
            " system\n",
            "\n",
            "You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
            "    1.  **Plan Generation:**\n",
            "      If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
            "      You MUST respond with the complete `{\"task_plans\": [...]}` JSON for the entire task.\n",
            "\n",
            "    2.  **Action Generation:**\n",
            "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
            "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.user\n",
            "\n",
            "{'user_request': '휴학신청'}assistant\n",
            "\n",
            "{\"task_plan\": [{\"step_id\": 1, \"task_plan\": \"좌측 메뉴에서 '졸업' 탭을 연다.\"}, {\"step_id\": 2, \"task_plan\": \"'취득학점취소/변경신청' 메뉴를 클릭하여 페이지로 이동한다.\"}, {\"step_id\": 3, \"task_plan\": \"'취득학점취소' 박스의 '학적' 항목의 체크박스를 해제한다.\"}, {\"step_id\": 4, \"task_plan\": \"'취소' 버튼을 클릭하여 신청 버튼을 활성화한다.\"}, {\"step_id\": 5, \"task_plan\": \"취소 버튼을 클릭한다.\"}]}\n",
            "\n",
            "[PARSED JSON - PLAN]\n",
            " {\"task_plans\": [...]}` JSON for the entire task.\n",
            "\n",
            "    2.  **Action Generation:**\n",
            "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
            "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.user\n",
            "\n",
            "{'user_request': '휴학신청'}assistant\n",
            "\n",
            "{\"task_plan\": [{\"step_id\": 1, \"task_plan\": \"좌측 메뉴에서 '졸업' 탭을 연다.\"}, {\"step_id\": 2, \"task_plan\": \"'취득학점취소/변경신청' 메뉴를 클릭하여 페이지로 이동한다.\"}, {\"step_id\": 3, \"task_plan\": \"'취득학점취소' 박스의 '학적' 항목의 체크박스를 해제한다.\"}, {\"step_id\": 4, \"task_plan\": \"'취소' 버튼을 클릭하여 신청 버튼을 활성화한다.\"}, {\"step_id\": 5, \"task_plan\": \"취소 버튼을 클릭한다.\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Dict, Any, Literal, List\n",
        "from outlines.models.transformers import Transformers\n",
        "from outlines import Generator\n",
        "\n",
        "# (가정: 'model'과 'tokenizer'는 이전 셀에서 로드 완료됨)\n",
        "if 'model' not in globals() or 'tokenizer' not in globals():\n",
        "    print(\"🚨 오류: 'model' 또는 'tokenizer'가 로드되지 않았습니다.\")\n",
        "    print(\"이 셀을 실행하기 전에 [14]번 셀 (모델 로드)을 먼저 실행해주세요.\")\n",
        "    # Colab에서 셀 실행을 중단하는 가장 간단한 방법\n",
        "    raise NameError(\"'model' or 'tokenizer' not defined.\")\n",
        "\n",
        "\n",
        "# --- 1. Pydantic 스키마 2개 정의 ---\n",
        "\n",
        "# ⭐️ Task A (Plan 생성)를 위한 스키마\n",
        "class Step(BaseModel):\n",
        "    step_id: int\n",
        "    description: str\n",
        "\n",
        "class TaskPlan(BaseModel):\n",
        "    task_plan: List[Step]\n",
        "\n",
        "# ⭐️ Task B (Action 생성)를 위한 스키마\n",
        "class ClickArgs(BaseModel):\n",
        "    role: str\n",
        "    aria_label: str = Field(alias=\"aria-label\")\n",
        "\n",
        "class ActionModel(BaseModel):\n",
        "    function: str\n",
        "    control_label: str\n",
        "    control_type: str\n",
        "    args: ClickArgs\n",
        "    status: Literal[\"CONTINUE\", \"FINISH\"]\n",
        "\n",
        "# --- 2. Outlines 제너레이터 2개 생성 ---\n",
        "# (두 제너레이터 모두 동일한 'model' 객체를 사용)\n",
        "\n",
        "print(f\"래핑할 모델 객체: {model.__class__.__name__}\") # PeftModelForCausalLM\n",
        "outlines_model = Transformers(model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Task A (Plan) 제너레이터\n",
        "plan_generator = Generator(outlines_model, TaskPlan)\n",
        "print(\"✅ 'Plan 생성기' 준비 완료.\")\n",
        "\n",
        "# Task B (Action) 제너레이터\n",
        "action_generator = Generator(outlines_model, ActionModel)\n",
        "print(\"✅ 'Action 생성기' 준비 완료.\")\n",
        "\n",
        "# --- 3. ⚡️ 상태(State) 정의 ⚡️ ---\n",
        "\n",
        "user_query = \"불교동아리\"\n",
        "\n",
        "# ⭐️ State 1: 1단계 (Plan 실행 전)의 '초기 상태'\n",
        "# (Cell [12]의 예시와 동일: 학생신청(기타)가 닫혀 있음)\n",
        "initial_state_json = {\n",
        "    \"sidebar\": [\n",
        "    {\n",
        "      \"label\": \"개인정보수집동의\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】신청함\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】진행함\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】완료함\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학생신청(기타)\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학적/확인서\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수강신청\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수업/강의평가\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"성적\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"장학\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"등록\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교직\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"졸업\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공학교육인증\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"현장실습\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"예비군\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교육센터\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"써머스쿨\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"남산학사\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"충무학사\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"고양학사\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공지사항\",\n",
        "      \"expanded\": True,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": [\n",
        "        {\n",
        "          \"label\": \"공지사항조회\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": True,\n",
        "          \"sub_items\": []\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "# ⭐️ State 2: 1단계 Action(\"학생신청(기타)\" 클릭)이 실행된 '이후의 상태'\n",
        "# (전체 JSON으로 확장된 버전. Python 변수이므로 true/false가 아닌 True/False 사용)\n",
        "state_after_step_1_json = {\n",
        "    \"sidebar\": [\n",
        "    {\n",
        "      \"label\": \"개인정보수집동의\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】신청함\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】진행함\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】완료함\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학생신청(기타)\",\n",
        "      \"expanded\": True,\n",
        "      \"checked\": True,\n",
        "      \"sub_items\": [\n",
        "        {\n",
        "          \"label\": \"봉사소감문등록\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"신행활동신청\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"신행활동마일리지점수확인\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"학생신행활동기준표안내\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교직이수신청/취소신청\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교육봉사활동시간등록\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"성인지교육신청\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"응급처치및심폐소생술 실습신청\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교직인적성검사 신청\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교직기타 서비스신청\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"DIY설문조사\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교류상황및파견정보등록\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"국외교류인정성적등록\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"해외학술탐방일정관리\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"근로장학근로시간등록\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"불교동아리가입\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"학생증개인정보동의\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"DEIS학부모서비스제공동의\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"투표하기\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학적/확인서\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수강신청\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수업/강의평가\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"성적\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"장학\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"등록\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교직\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"졸업\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공학교육인증\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"현장실습\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"예비군\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교육센터\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"써머스쿨\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"남산학사\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"충무학사\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"고양학사\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공지사항\",\n",
        "      \"expanded\": False,\n",
        "      \"checked\": False,\n",
        "      \"sub_items\": [\n",
        "        {\n",
        "          \"label\": \"공지사항조회\",\n",
        "          \"expanded\": False,\n",
        "          \"checked\": False,\n",
        "          \"sub_items\": []\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "\n",
        "# --- 4. ⚡️ 자동화 파이프라인(루프) 실행 ⚡️ ---\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    # === 1단계: Query ➡️ Plan ===\n",
        "    print(f\"\\n--- 1단계: '{user_query}'로 Plan 생성 ---\")\n",
        "\n",
        "    plan_messages = [\n",
        "        {\"role\": \"system\",\n",
        "      \"content\": \"\"\"You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
        "      1.  **Plan Generation:**\n",
        "        If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
        "        You MUST respond with the complete `{\"task_plans\": [...]}` JSON for the entire task.\n",
        "\n",
        "      2.  **Action Generation:**\n",
        "        If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
        "        You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.\"\"\"},\n",
        "        {\"role\": \"user_request\", \"content\": user_query}\n",
        "    ]\n",
        "    plan_prompt_string = tokenizer.apply_chat_template(\n",
        "        plan_messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    generated_plan_obj = None # Pydantic 객체를 담을 변수\n",
        "    try:\n",
        "        # Pydantic 객체를 반환하도록 시도\n",
        "        generated_plan_str_or_obj = plan_generator(plan_prompt_string, max_new_tokens=256)\n",
        "\n",
        "        # Pydantic 객체가 반환되었는지, 문자열이 반환되었는지 확인\n",
        "        if isinstance(generated_plan_str_or_obj, str):\n",
        "            print(f\"⚠️ 1단계 경고: Outlines가 문자열 반환. 수동 파싱 시도...\")\n",
        "            print(f\"   반환된 원본(str): {generated_plan_str_or_obj}\")\n",
        "            json_data = json.loads(generated_plan_str_or_obj)\n",
        "            generated_plan_obj = TaskPlan.model_validate(json_data)\n",
        "        else:\n",
        "            generated_plan_obj = generated_plan_str_or_obj # Pydantic 객체\n",
        "\n",
        "        print(\"   ✅ 1단계 Plan 생성 성공!\")\n",
        "        print(generated_plan_obj.model_dump_json(indent=2))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"🚨 1단계 오류: Plan 생성 또는 파싱 실패: {e}\")\n",
        "        # 1단계가 실패하면 2단계를 실행할 수 없으므로 중단\n",
        "        raise Exception(\"1단계 Plan 생성 실패\")\n",
        "\n",
        "\n",
        "    # === 2단계: (Plan + State) ➡️ Action (루프 실행) ===\n",
        "\n",
        "    # ⭐️ 첫 번째 상태는 '초기 상태'로 설정\n",
        "    current_state = initial_state_json\n",
        "\n",
        "    # 생성된 Plan의 모든 단계를 순회\n",
        "    for i, step in enumerate(generated_plan_obj.task_plan):\n",
        "\n",
        "        step_description = step.description\n",
        "        print(f\"\\n--- 2단계 (Step {i+1}): '{step_description}'으로 Action 생성 ---\")\n",
        "\n",
        "        # ⭐️ Task B 프롬프트 (현재 state를 사용)\n",
        "        action_messages = [\n",
        "            {\"role\": \"system\",\n",
        "    \"content\": \"\"\"You are a specialized AI agent for Dongguk Univ nDRIMS. Your task is to analyze the user's input structure and perform one of two specific tasks:\n",
        "    1.  **Plan Generation:**\n",
        "      If the user 'prompt' contains **only** a `user_request` (e.g., \"불교동아리 가입\"), this is a request for a plan.\n",
        "      You MUST respond with the complete `{\"task_plans\": [...]}` JSON for the entire task.\n",
        "\n",
        "    2.  **Action Generation:**\n",
        "      If the user 'prompt' contains a `task_plan` (current step) AND `observations` (current state), this is a request for an action.\n",
        "      You MUST respond with the single `{\"action\": {...}}` JSON for that specific step.\"\"\"},\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"\n",
        "            {{'user_request': '불교동아리',\n",
        "              'task_plan': '{step_description}',\n",
        "              'step_id': f'{i+1}',\n",
        "              'observations': {json.dumps(current_state, ensure_ascii=False)}}}\n",
        "            \"\"\"},\n",
        "        ]\n",
        "        action_prompt_string = tokenizer.apply_chat_template(\n",
        "            action_messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        action_result_obj = None # Pydantic 객체를 담을 변수\n",
        "        try:\n",
        "            action_result_str_or_obj = action_generator(action_prompt_string, max_new_tokens=256)\n",
        "\n",
        "            # Pydantic 객체/문자열 반환 여부 확인\n",
        "            if isinstance(action_result_str_or_obj, str):\n",
        "                print(f\"⚠️ 2단계 경고: Outlines가 문자열 반환. 수동 파싱 시도...\")\n",
        "                print(f\"   반환된 원본(str): {action_result_str_or_obj}\")\n",
        "                json_data = json.loads(action_result_str_or_obj)\n",
        "                action_result_obj = ActionModel.model_validate(json_data)\n",
        "            else:\n",
        "                action_result_obj = action_result_str_or_obj # Pydantic 객체\n",
        "\n",
        "            print(\"\\n--- ⭐️ Action JSON 출력 (Step {i+1}) ⭐️ ---\")\n",
        "            print(action_result_obj.model_dump_json(indent=2))\n",
        "\n",
        "            # === 3단계: ⭐️ 상태 업데이트 (시뮬레이션) ⭐️ ===\n",
        "            if action_result_obj.status == \"FINISH\":\n",
        "                print(\"\\n[INFO] 'FINISH' 상태이므로 루프를 종료합니다.\")\n",
        "                break\n",
        "            else:\n",
        "                # (시뮬레이션) 1단계가 끝났으니, 2단계를 위해 상태를 업데이트합니다.\n",
        "                print(\"[INFO] (시뮬레이션) Action 실행... 다음 단계를 위해 상태를 업데이트합니다.\")\n",
        "\n",
        "                # ⭐️⭐️⭐️\n",
        "                # 1단계(\"학생신청(기타)\" 클릭)가 실행되었으므로,\n",
        "                # 다음 루프에서 사용할 상태를 'state_after_step_1_json'로 변경합니다.\n",
        "                # ⭐️⭐️⭐️\n",
        "                current_state = state_after_step_1_json\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"🚨 2단계 (Step {i+1}) 실행 중 오류: {e}\")\n",
        "            break # 오류 발생 시 루프 중단\n",
        "\n",
        "    print(\"\\n--- 🚀 전체 파이프라인 실행 완료 ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsyZPQyrSACh",
        "outputId": "c0a08335-e420-4229-86ed-239c322a815f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "래핑할 모델 객체: PeftModelForCausalLM\n",
            "✅ 'Plan 생성기' 준비 완료.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 'Action 생성기' 준비 완료.\n",
            "\n",
            "--- 1단계: '불교동아리'로 Plan 생성 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ 1단계 경고: Outlines가 문자열 반환. 수동 파싱 시도...\n",
            "   반환된 원본(str): {\"task_plan\": [{\"step_id\": 1, \"description\": \"좌측 메뉴에서 '학생신청(기타)'를 클릭한다.\"}, {\"step_id\": 2, \"description\": \"'불교동아리가입' 메뉴를 클릭한다.\"}]}\n",
            "   ✅ 1단계 Plan 생성 성공!\n",
            "{\n",
            "  \"task_plan\": [\n",
            "    {\n",
            "      \"step_id\": 1,\n",
            "      \"description\": \"좌측 메뉴에서 '학생신청(기타)'를 클릭한다.\"\n",
            "    },\n",
            "    {\n",
            "      \"step_id\": 2,\n",
            "      \"description\": \"'불교동아리가입' 메뉴를 클릭한다.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- 2단계 (Step 1): '좌측 메뉴에서 '학생신청(기타)'를 클릭한다.'으로 Action 생성 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ 2단계 경고: Outlines가 문자열 반환. 수동 파싱 시도...\n",
            "   반환된 원본(str): {\"function\": \"click\", \"control_label\": \"학생신청(기타)\", \"control_type\": \"tree-item\", \"args\": {\"role\": \"treeitem\", \"aria-label\": \"학생신청(기타)\"}, \"status\": \"CONTINUE\"}\n",
            "\n",
            "--- ⭐️ Action JSON 출력 (Step {i+1}) ⭐️ ---\n",
            "{\n",
            "  \"function\": \"click\",\n",
            "  \"control_label\": \"학생신청(기타)\",\n",
            "  \"control_type\": \"tree-item\",\n",
            "  \"args\": {\n",
            "    \"role\": \"treeitem\",\n",
            "    \"aria_label\": \"학생신청(기타)\"\n",
            "  },\n",
            "  \"status\": \"CONTINUE\"\n",
            "}\n",
            "[INFO] (시뮬레이션) Action 실행... 다음 단계를 위해 상태를 업데이트합니다.\n",
            "\n",
            "--- 2단계 (Step 2): ''불교동아리가입' 메뉴를 클릭한다.'으로 Action 생성 ---\n",
            "⚠️ 2단계 경고: Outlines가 문자열 반환. 수동 파싱 시도...\n",
            "   반환된 원본(str): {\"function\": \"click\", \"control_label\": \"불교동아리가입\", \"control_type\": \"tree-item\", \"args\": {\"role\": \"treeitem\", \"aria-label\": \"불교동아리가입\"}, \"status\": \"CONTINUE\"}\n",
            "\n",
            "--- ⭐️ Action JSON 출력 (Step {i+1}) ⭐️ ---\n",
            "{\n",
            "  \"function\": \"click\",\n",
            "  \"control_label\": \"불교동아리가입\",\n",
            "  \"control_type\": \"tree-item\",\n",
            "  \"args\": {\n",
            "    \"role\": \"treeitem\",\n",
            "    \"aria_label\": \"불교동아리가입\"\n",
            "  },\n",
            "  \"status\": \"CONTINUE\"\n",
            "}\n",
            "[INFO] (시뮬레이션) Action 실행... 다음 단계를 위해 상태를 업데이트합니다.\n",
            "\n",
            "--- 🚀 전체 파이프라인 실행 완료 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NKiXh9VPXim",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "3fad0c3c-b6fa-4093-cf79-a0921b4e8249"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-915838778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"요청사항을 입력하세요: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m messages = [\n\u001b[1;32m      4\u001b[0m     {\"role\": \"system\",\n\u001b[1;32m      5\u001b[0m     \"content\": \"You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's request\"},\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "user_input = input(\"요청사항을 입력하세요: \")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\",\n",
        "    \"content\": \"You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state)+ step-by-step plan + the user's request\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "    {'user_request': '{user_input}',\n",
        "     'observations': \"sidebar\": [\n",
        "    {\n",
        "      \"label\": \"개인정보수집동의\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】신청함\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】진행함\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】완료함\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학생신청(기타)\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학적/확인서\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수강신청\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수업/강의평가\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"성적\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"장학\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"등록\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교직\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"졸업\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공학교육인증\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"현장실습\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"예비군\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교육센터\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"써머스쿨\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"남산학사\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"충무학사\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"고양학사\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공지사항\",\n",
        "      \"expanded\": true,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": [\n",
        "        {\n",
        "          \"label\": \"공지사항조회\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": true,\n",
        "          \"sub_items\": []\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}}]}\n",
        "    \"\"\"},\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True)\n",
        "\n",
        "    input_ids = torch.tensor([ids]).to(\"cuda\")\n",
        "    input_length = input_ids.shape[1]\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=64,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "    generated_tokens = output[0][input_length:]\n",
        "    extracted_response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "print(\"\\n--- Action step1 ---\")\n",
        "print(extracted_response)\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\",\n",
        "    \"content\": \"You are a helpful AI assistant for Dongguk Univ nDRIMS. Your job is to understand the user's request, formulate a step-by-step plan, and then output the correct action based on the current system observations (state).\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "    {'user_request': '{user_input}',\n",
        "     'observations':  \"sidebar\": [\n",
        "    {\n",
        "      \"label\": \"개인정보수집동의\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】신청함\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】진행함\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"【학생신청】완료함\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학생신청(기타)\",\n",
        "      \"expanded\": true,\n",
        "      \"checked\": true,\n",
        "      \"sub_items\": [\n",
        "        {\n",
        "          \"label\": \"봉사소감문등록\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"신행활동신청\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"신행활동마일리지점수확인\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"학생신행활동기준표안내\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교직이수신청/취소신청\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교육봉사활동시간등록\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"성인지교육신청\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"응급처치및심폐소생술 실습신청\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교직인적성검사 신청\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교직기타 서비스신청\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"DIY설문조사\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"교류상황및파견정보등록\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"국외교류인정성적등록\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"해외학술탐방일정관리\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"근로장학근로시간등록\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"불교동아리가입\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"학생증개인정보동의\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"DEIS학부모서비스제공동의\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        },\n",
        "        {\n",
        "          \"label\": \"투표하기\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"학적/확인서\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수강신청\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"수업/강의평가\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"성적\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"장학\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"등록\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교직\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"졸업\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공학교육인증\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"현장실습\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"예비군\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"교육센터\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"써머스쿨\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"남산학사\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"충무학사\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"고양학사\",\n",
        "      \"expanded\": false,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": []\n",
        "    },\n",
        "    {\n",
        "      \"label\": \"공지사항\",\n",
        "      \"expanded\": true,\n",
        "      \"checked\": false,\n",
        "      \"sub_items\": [\n",
        "        {\n",
        "          \"label\": \"공지사항조회\",\n",
        "          \"expanded\": false,\n",
        "          \"checked\": false,\n",
        "          \"sub_items\": []\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}}]}}}\n",
        "    \"\"\"},\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True)\n",
        "\n",
        "    input_ids = torch.tensor([ids]).to(\"cuda\")\n",
        "    input_length = input_ids.shape[1]\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=64,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "    generated_tokens = output[0][input_length:]\n",
        "    extracted_response2 = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "print(\"\\n--- Action step2 ---\")\n",
        "print(extracted_response2)\n",
        "# extracted_response 변수에 JSON 형태의 문자열이 저장됨\n",
        "# {'function': 'click', 'control_label': '취득학점확인서조회', ... 'status': 'FINISH'}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMjobb6ZPv5jZUsXApSUnxV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "326a907679c547ceb91d31ae29093c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_eb8e335e2a25474ab51038d1086bd691"
          }
        },
        "8f9840504fce49728aeee44c5de76ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04512b6707d84b519b572ab4fc1e946e",
            "placeholder": "​",
            "style": "IPY_MODEL_980449282b6f46c8bdb101912d695567",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "6d6a9e12155c486bb81216418477c7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_83a70e39556544aaa33768c141c65f27",
            "placeholder": "​",
            "style": "IPY_MODEL_951b67b21f7341ae99e1b653894973a1",
            "value": ""
          }
        },
        "28cc0b7a0a79402287b51c61fe003c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d8305bae8a0740a986698182e73dd8d4",
            "style": "IPY_MODEL_c8022be555644084a0388fd2814bae31",
            "value": true
          }
        },
        "bce08e409d5449a9bc3f179c71a7bf4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_787a5ed0b08543af8d78736b1f9ec947",
            "style": "IPY_MODEL_4ee4d62335cf4cc09b347d4978812931",
            "tooltip": ""
          }
        },
        "69b039c24e424c1ebdc448a31aeb6651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d574d3627e340ec87cd0efc1d3e117a",
            "placeholder": "​",
            "style": "IPY_MODEL_cebbc437fa874bf68fb1c28d758e6c78",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "eb8e335e2a25474ab51038d1086bd691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "04512b6707d84b519b572ab4fc1e946e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980449282b6f46c8bdb101912d695567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83a70e39556544aaa33768c141c65f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951b67b21f7341ae99e1b653894973a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8305bae8a0740a986698182e73dd8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8022be555644084a0388fd2814bae31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787a5ed0b08543af8d78736b1f9ec947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee4d62335cf4cc09b347d4978812931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6d574d3627e340ec87cd0efc1d3e117a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cebbc437fa874bf68fb1c28d758e6c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d360f26f00e4b0cb120f5e18f6959a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa4c0caa3194a3b9150a34613301ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_56761b43ca0c495eafd8747260cfadce",
            "value": "Connecting..."
          }
        },
        "5fa4c0caa3194a3b9150a34613301ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56761b43ca0c495eafd8747260cfadce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a178ede343764e99a0b494040d0dc3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d0572b343ff48589a174e32dacf0aa8",
              "IPY_MODEL_9d5f34d61b9e4da298d1f7532891699e",
              "IPY_MODEL_07d5a06f841f42cdbe0fbf360575eb19"
            ],
            "layout": "IPY_MODEL_adf078c44c83474384ee18b72ff9ccd3"
          }
        },
        "0d0572b343ff48589a174e32dacf0aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c3a8d4455c4a5fba60e9ab51b28677",
            "placeholder": "​",
            "style": "IPY_MODEL_3e0446f5cd6d4af591574b54d55d0ee1",
            "value": "Processing Files (2 / 2)      : 100%"
          }
        },
        "9d5f34d61b9e4da298d1f7532891699e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67fc1f6e6afc439cb6aad08d36ba845f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8eb42b0a7d247e6978779e1d4747890",
            "value": 1
          }
        },
        "07d5a06f841f42cdbe0fbf360575eb19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3adf2ce192bd402c8eab2344b7155740",
            "placeholder": "​",
            "style": "IPY_MODEL_42d294d07a364f0da71bb20bf18d2d5b",
            "value": "  109MB /  109MB, 12.1MB/s  "
          }
        },
        "adf078c44c83474384ee18b72ff9ccd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c3a8d4455c4a5fba60e9ab51b28677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0446f5cd6d4af591574b54d55d0ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67fc1f6e6afc439cb6aad08d36ba845f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b8eb42b0a7d247e6978779e1d4747890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3adf2ce192bd402c8eab2344b7155740": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d294d07a364f0da71bb20bf18d2d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8da0739ff2654f26b4c8533b49ae9879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41e872ea982f4c3e85c4c2b762d888e1",
              "IPY_MODEL_62a1a383481b4012a905bf524766997f",
              "IPY_MODEL_a70113a48f3741b3b7187ef3daed523e"
            ],
            "layout": "IPY_MODEL_802c626be90b49d1b3bfd73a60f208a5"
          }
        },
        "41e872ea982f4c3e85c4c2b762d888e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df21bb2c439f4df7907a2cc0b7efbb48",
            "placeholder": "​",
            "style": "IPY_MODEL_2c4675f6e9754073bac6d4b150df46d3",
            "value": "New Data Upload               : 100%"
          }
        },
        "62a1a383481b4012a905bf524766997f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e26c1b57fce436596abd240bcfab5d1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f98a4a8ee6f145b384538f8518a3afad",
            "value": 1
          }
        },
        "a70113a48f3741b3b7187ef3daed523e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8464eaa52e8e48f097da42bb484bc94b",
            "placeholder": "​",
            "style": "IPY_MODEL_974fe201f925432bb1a0bf7f1661340a",
            "value": " 92.1MB / 92.1MB, 10.2MB/s  "
          }
        },
        "802c626be90b49d1b3bfd73a60f208a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df21bb2c439f4df7907a2cc0b7efbb48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4675f6e9754073bac6d4b150df46d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e26c1b57fce436596abd240bcfab5d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f98a4a8ee6f145b384538f8518a3afad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8464eaa52e8e48f097da42bb484bc94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "974fe201f925432bb1a0bf7f1661340a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e53b3429fb3740c8aa8288aef548398d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f810fc63cca34b3280a0232edc5ebc06",
              "IPY_MODEL_b2b683c47c5b47b78ab4e920836a35f2",
              "IPY_MODEL_7ec89d8f36c244869d154ea9909d18d2"
            ],
            "layout": "IPY_MODEL_3bb16a5120b5448188136489598f325c"
          }
        },
        "f810fc63cca34b3280a0232edc5ebc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69943c5a394c426b8650dddc54f2648f",
            "placeholder": "​",
            "style": "IPY_MODEL_7a955e8436ca4cb1aba052b8f11f8c10",
            "value": "  .../epoch_009/tokenizer.json: 100%"
          }
        },
        "b2b683c47c5b47b78ab4e920836a35f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685f04b682c34aafa6d3bac42fcca6c9",
            "max": 17209961,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7786cc6fbf14b7f9fe2512e9946be43",
            "value": 17209961
          }
        },
        "7ec89d8f36c244869d154ea9909d18d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9259edeaf3f5474c8c302f5db4ac3c60",
            "placeholder": "​",
            "style": "IPY_MODEL_51a2aff44c12484fb6a67e305c773ee4",
            "value": " 17.2MB / 17.2MB            "
          }
        },
        "3bb16a5120b5448188136489598f325c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69943c5a394c426b8650dddc54f2648f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a955e8436ca4cb1aba052b8f11f8c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "685f04b682c34aafa6d3bac42fcca6c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7786cc6fbf14b7f9fe2512e9946be43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9259edeaf3f5474c8c302f5db4ac3c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a2aff44c12484fb6a67e305c773ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3628ab2a40214626b04b6f63f6b1549f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83aa42a617eb48c99196c0121d02a59a",
              "IPY_MODEL_e370524be2ea43c1ab631ad1a9bcf83d",
              "IPY_MODEL_4c70b7fa1caf4b7b9e5f6283938c6900"
            ],
            "layout": "IPY_MODEL_ac28a8b464f24135a46ccd944ea19183"
          }
        },
        "83aa42a617eb48c99196c0121d02a59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_345ee026e0a24f33b338891081e97f55",
            "placeholder": "​",
            "style": "IPY_MODEL_53036b8d4ee2445ea4ac78bc9f29d255",
            "value": "  ...adapter_model.safetensors: 100%"
          }
        },
        "e370524be2ea43c1ab631ad1a9bcf83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_598fd38ecc604290a78b9ca990b1b539",
            "max": 92072120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24992079bab84a98a444d5686ffbfd59",
            "value": 92072120
          }
        },
        "4c70b7fa1caf4b7b9e5f6283938c6900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e17a97ddfd8f486fa55b2852fee5e47e",
            "placeholder": "​",
            "style": "IPY_MODEL_3ac934d066da4302a74451f3ac0ffa91",
            "value": " 92.1MB / 92.1MB            "
          }
        },
        "ac28a8b464f24135a46ccd944ea19183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345ee026e0a24f33b338891081e97f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53036b8d4ee2445ea4ac78bc9f29d255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "598fd38ecc604290a78b9ca990b1b539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24992079bab84a98a444d5686ffbfd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e17a97ddfd8f486fa55b2852fee5e47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac934d066da4302a74451f3ac0ffa91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "433fce82550f49ca8abca1a61393bb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_47e98a7a8e4440188b2cb5877e750143"
          }
        },
        "0e2487c169354c329f5d9a8c616ceb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5b16a11806840769bd72c6570ba3920",
            "placeholder": "​",
            "style": "IPY_MODEL_b20074e7cca54adf9a287ffe67fc012e",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "c1d0bc1558d04983b515f1ec49ea1b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7f9689ad68e44ac0b716c0c63919cd9d",
            "placeholder": "​",
            "style": "IPY_MODEL_18e1d224a3be493f8ba1566d8f81bca5",
            "value": ""
          }
        },
        "7220bd378c8a4bcd9862da23cfc5f5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_21bc55f894764f1590cc070f337a0322",
            "style": "IPY_MODEL_c45a2655c38746fa900eab450500c405",
            "value": true
          }
        },
        "4dc3e08c903a4f54852ba1ffe2e53d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cb2937bc11e5424bba935fccf2613d82",
            "style": "IPY_MODEL_b71ae1f0e60c48ffa477d3270abb796c",
            "tooltip": ""
          }
        },
        "b6811149866842e59fdc8b39ead3e284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e6e798befd74335a66e95dff6fb30e6",
            "placeholder": "​",
            "style": "IPY_MODEL_f61ae4b4efb441bfba541934b89f836b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "47e98a7a8e4440188b2cb5877e750143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e5b16a11806840769bd72c6570ba3920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b20074e7cca54adf9a287ffe67fc012e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f9689ad68e44ac0b716c0c63919cd9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e1d224a3be493f8ba1566d8f81bca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21bc55f894764f1590cc070f337a0322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c45a2655c38746fa900eab450500c405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb2937bc11e5424bba935fccf2613d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71ae1f0e60c48ffa477d3270abb796c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9e6e798befd74335a66e95dff6fb30e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61ae4b4efb441bfba541934b89f836b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1e0675587ee4572aebb019ec1cf5871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b3b49d59f74af2adda1464db01ceb6",
            "placeholder": "​",
            "style": "IPY_MODEL_c53192f8cfcd4d029cb8afb307972248",
            "value": "Connecting..."
          }
        },
        "a7b3b49d59f74af2adda1464db01ceb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53192f8cfcd4d029cb8afb307972248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}